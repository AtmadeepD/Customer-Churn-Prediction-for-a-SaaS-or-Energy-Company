{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":12046136,"sourceType":"datasetVersion","datasetId":7580585}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\n\ndf = pd.read_csv('/kaggle/input/processed-churn-data/processed_churn_data.csv')\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-03T10:50:15.305104Z","iopub.execute_input":"2025-06-03T10:50:15.305513Z","iopub.status.idle":"2025-06-03T10:50:15.769083Z","shell.execute_reply.started":"2025-06-03T10:50:15.305488Z","shell.execute_reply":"2025-06-03T10:50:15.768037Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import sklearn\nprint(\"scikit-learn version:\", sklearn.__version__)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T10:50:15.770100Z","iopub.execute_input":"2025-06-03T10:50:15.770367Z","iopub.status.idle":"2025-06-03T10:50:16.298855Z","shell.execute_reply.started":"2025-06-03T10:50:15.770345Z","shell.execute_reply":"2025-06-03T10:50:16.297951Z"}},"outputs":[{"name":"stdout","text":"scikit-learn version: 1.2.2\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import imblearn\nprint(\"imbalanced-learn version:\", imblearn.__version__)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T10:50:16.299841Z","iopub.execute_input":"2025-06-03T10:50:16.300365Z","iopub.status.idle":"2025-06-03T10:50:16.570934Z","shell.execute_reply.started":"2025-06-03T10:50:16.300333Z","shell.execute_reply":"2025-06-03T10:50:16.564374Z"}},"outputs":[{"name":"stdout","text":"imbalanced-learn version: 0.10.1\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import pandas as pd\nfrom catboost import CatBoostClassifier\nfrom sklearn.metrics import classification_report, roc_auc_score\nfrom sklearn.model_selection import train_test_split\nfrom imblearn.over_sampling import SMOTE\n\n# Assuming 'df' is your fully processed DataFrame with features & target 'Churn'\nX = df.drop(columns=['Churn'])\ny = df['Churn']\n\n# Split again just to ensure reproducibility\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n\n# Apply SMOTE to balance classes on training set only\nsmote = SMOTE(random_state=42)\nX_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n\nprint(f\"After SMOTE, training data shape: {X_train_smote.shape}, Churn distribution: {y_train_smote.value_counts(normalize=True)}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T10:50:16.572192Z","iopub.execute_input":"2025-06-03T10:50:16.572602Z","iopub.status.idle":"2025-06-03T10:50:17.506080Z","shell.execute_reply.started":"2025-06-03T10:50:16.572488Z","shell.execute_reply":"2025-06-03T10:50:17.505024Z"}},"outputs":[{"name":"stdout","text":"After SMOTE, training data shape: (8260, 26), Churn distribution: Churn\n0    0.5\n1    0.5\nName: proportion, dtype: float64\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"print(f\"After SMOTE, training data shape: {X_train_smote.shape}, Churn distribution: {y_train_smote.value_counts(normalize=True)}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T10:51:07.382242Z","iopub.execute_input":"2025-06-03T10:51:07.382649Z","iopub.status.idle":"2025-06-03T10:51:07.389967Z","shell.execute_reply.started":"2025-06-03T10:51:07.382618Z","shell.execute_reply":"2025-06-03T10:51:07.388940Z"}},"outputs":[{"name":"stdout","text":"After SMOTE, training data shape: (8260, 26), Churn distribution: Churn\n0    0.5\n1    0.5\nName: proportion, dtype: float64\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"from catboost import CatBoostClassifier\nfrom sklearn.metrics import classification_report, roc_auc_score, confusion_matrix\n\n# Initialize CatBoostClassifier with some strong baseline parameters\nmodel = CatBoostClassifier(\n    iterations=1000,          # Number of boosting iterations\n    learning_rate=0.05,       # Moderate learning rate\n    depth=6,                  # Tree depth\n    eval_metric='AUC',        # Use AUC as evaluation metric\n    random_seed=42,\n    early_stopping_rounds=50, # Stop if no improvement after 50 rounds\n    verbose=100               # Print training progress every 100 iterations\n)\n\n# Train the model on SMOTE balanced training data\nmodel.fit(\n    X_train_smote, y_train_smote,\n    eval_set=(X_test, y_test),  # Validate on original test data (unbalanced)\n    use_best_model=True         # Use the best iteration based on validation score\n)\n\n# Predict probabilities and classes on the test set\ny_pred_proba = model.predict_proba(X_test)[:, 1]\ny_pred = model.predict(X_test)\n\n# Metrics\nprint(\"Classification Report:\")\nprint(classification_report(y_test, y_pred))\n\nroc_auc = roc_auc_score(y_test, y_pred_proba)\nprint(f\"ROC AUC Score: {roc_auc:.4f}\")\n\n# Optional: Confusion Matrix to see true positives/negatives\ncm = confusion_matrix(y_test, y_pred)\nprint(\"Confusion Matrix:\")\nprint(cm)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T10:51:51.416831Z","iopub.execute_input":"2025-06-03T10:51:51.417136Z","iopub.status.idle":"2025-06-03T10:51:51.974351Z","shell.execute_reply.started":"2025-06-03T10:51:51.417114Z","shell.execute_reply":"2025-06-03T10:51:51.973489Z"}},"outputs":[{"name":"stdout","text":"0:\ttest: 0.8108981\tbest: 0.8108981 (0)\ttotal: 57.2ms\tremaining: 57.1s\nStopped by overfitting detector  (50 iterations wait)\n\nbestTest = 0.8304805069\nbestIteration = 33\n\nShrink model to first 34 iterations.\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.90      0.74      0.81      1033\n           1       0.51      0.76      0.61       374\n\n    accuracy                           0.75      1407\n   macro avg       0.71      0.75      0.71      1407\nweighted avg       0.79      0.75      0.76      1407\n\nROC AUC Score: 0.8305\nConfusion Matrix:\n[[764 269]\n [ 89 285]]\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"from catboost import CatBoostClassifier\nfrom sklearn.metrics import classification_report, roc_auc_score\nfrom sklearn.model_selection import train_test_split\nfrom imblearn.over_sampling import SMOTE\n\n# Assuming df, X, y, X_train, X_test, y_train, y_test are already defined\n\nsmote = SMOTE(random_state=42)\nX_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n\n# Define a few hyperparameter combinations to try\nparam_grid = [\n    {'depth': 4, 'learning_rate': 0.1, 'iterations': 100},\n    {'depth': 6, 'learning_rate': 0.05, 'iterations': 200},\n    {'depth': 8, 'learning_rate': 0.03, 'iterations': 300},\n]\n\nbest_auc = 0\nbest_model = None\n\nfor params in param_grid:\n    print(f\"Training with params: {params}\")\n    model = CatBoostClassifier(\n        **params,\n        random_seed=42,\n        early_stopping_rounds=50,\n        verbose=50,\n        loss_function='Logloss',\n        eval_metric='AUC'\n    )\n    model.fit(X_train_smote, y_train_smote, eval_set=(X_test, y_test), use_best_model=True)\n    \n    y_pred = model.predict(X_test)\n    y_proba = model.predict_proba(X_test)[:,1]\n    \n    auc = roc_auc_score(y_test, y_proba)\n    print(f\"AUC: {auc:.4f}\")\n    \n    if auc > best_auc:\n        best_auc = auc\n        best_model = model\n    \n    print(classification_report(y_test, y_pred))\n\nprint(f\"Best AUC after tuning: {best_auc:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T10:54:17.577178Z","iopub.execute_input":"2025-06-03T10:54:17.577595Z","iopub.status.idle":"2025-06-03T10:54:18.944192Z","shell.execute_reply.started":"2025-06-03T10:54:17.577565Z","shell.execute_reply":"2025-06-03T10:54:18.943422Z"}},"outputs":[{"name":"stdout","text":"Training with params: {'depth': 4, 'learning_rate': 0.1, 'iterations': 100}\n0:\ttest: 0.8069418\tbest: 0.8069418 (0)\ttotal: 3.63ms\tremaining: 360ms\n50:\ttest: 0.8293792\tbest: 0.8307290 (35)\ttotal: 160ms\tremaining: 154ms\nStopped by overfitting detector  (50 iterations wait)\n\nbestTest = 0.8307289914\nbestIteration = 35\n\nShrink model to first 36 iterations.\nAUC: 0.8307\n              precision    recall  f1-score   support\n\n           0       0.90      0.73      0.81      1033\n           1       0.52      0.78      0.62       374\n\n    accuracy                           0.75      1407\n   macro avg       0.71      0.76      0.72      1407\nweighted avg       0.80      0.75      0.76      1407\n\nTraining with params: {'depth': 6, 'learning_rate': 0.05, 'iterations': 200}\n0:\ttest: 0.8108981\tbest: 0.8108981 (0)\ttotal: 5.13ms\tremaining: 1.02s\n50:\ttest: 0.8299641\tbest: 0.8304805 (33)\ttotal: 213ms\tremaining: 622ms\nStopped by overfitting detector  (50 iterations wait)\n\nbestTest = 0.8304805069\nbestIteration = 33\n\nShrink model to first 34 iterations.\nAUC: 0.8305\n              precision    recall  f1-score   support\n\n           0       0.90      0.74      0.81      1033\n           1       0.51      0.76      0.61       374\n\n    accuracy                           0.75      1407\n   macro avg       0.71      0.75      0.71      1407\nweighted avg       0.79      0.75      0.76      1407\n\nTraining with params: {'depth': 8, 'learning_rate': 0.03, 'iterations': 300}\n0:\ttest: 0.8198552\tbest: 0.8198552 (0)\ttotal: 9.11ms\tremaining: 2.72s\n50:\ttest: 0.8264167\tbest: 0.8275401 (19)\ttotal: 359ms\tremaining: 1.75s\nStopped by overfitting detector  (50 iterations wait)\n\nbestTest = 0.827540107\nbestIteration = 19\n\nShrink model to first 20 iterations.\nAUC: 0.8275\n              precision    recall  f1-score   support\n\n           0       0.90      0.73      0.81      1033\n           1       0.51      0.77      0.61       374\n\n    accuracy                           0.74      1407\n   macro avg       0.70      0.75      0.71      1407\nweighted avg       0.79      0.74      0.76      1407\n\nBest AUC after tuning: 0.8307\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.metrics import precision_recall_curve\n\n# Use your best_model from tuning step\ny_proba = best_model.predict_proba(X_test)[:, 1]\n\nprecisions, recalls, thresholds = precision_recall_curve(y_test, y_proba)\n\n# Find threshold with best precision-recall balance (you can pick your own preference)\nfor p, r, t in zip(precisions, recalls, np.append(thresholds, 1)):\n    print(f\"Threshold: {t:.2f}, Precision: {p:.2f}, Recall: {r:.2f}\")\n\n# Pick a threshold for higher precision (e.g., 0.6 or 0.7) and evaluate\n\nchosen_threshold = 0.6\ny_pred_thresh = (y_proba >= chosen_threshold).astype(int)\n\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\nprint(\"Classification Report at threshold\", chosen_threshold)\nprint(classification_report(y_test, y_pred_thresh))\nprint(\"Confusion Matrix:\")\nprint(confusion_matrix(y_test, y_pred_thresh))\nprint(\"ROC AUC Score:\", roc_auc_score(y_test, y_proba))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T10:54:53.220731Z","iopub.execute_input":"2025-06-03T10:54:53.221079Z","iopub.status.idle":"2025-06-03T10:54:53.253081Z","shell.execute_reply.started":"2025-06-03T10:54:53.221053Z","shell.execute_reply":"2025-06-03T10:54:53.251973Z"}},"outputs":[{"name":"stdout","text":"Threshold: 0.02, Precision: 0.27, Recall: 1.00\nThreshold: 0.02, Precision: 0.27, Recall: 1.00\nThreshold: 0.02, Precision: 0.27, Recall: 1.00\nThreshold: 0.03, Precision: 0.27, Recall: 1.00\nThreshold: 0.03, Precision: 0.27, Recall: 1.00\nThreshold: 0.03, Precision: 0.27, Recall: 1.00\nThreshold: 0.03, Precision: 0.27, Recall: 1.00\nThreshold: 0.03, Precision: 0.27, Recall: 1.00\nThreshold: 0.03, Precision: 0.27, Recall: 0.99\nThreshold: 0.03, Precision: 0.27, Recall: 0.99\nThreshold: 0.03, Precision: 0.27, Recall: 0.99\nThreshold: 0.03, Precision: 0.27, Recall: 0.99\nThreshold: 0.03, Precision: 0.27, Recall: 0.99\nThreshold: 0.03, Precision: 0.27, Recall: 0.99\nThreshold: 0.03, Precision: 0.27, Recall: 0.99\nThreshold: 0.03, Precision: 0.27, Recall: 0.99\nThreshold: 0.03, Precision: 0.27, Recall: 0.99\nThreshold: 0.03, Precision: 0.27, Recall: 0.99\nThreshold: 0.03, Precision: 0.27, Recall: 0.99\nThreshold: 0.03, Precision: 0.27, Recall: 0.99\nThreshold: 0.03, Precision: 0.27, Recall: 0.99\nThreshold: 0.03, Precision: 0.27, Recall: 0.99\nThreshold: 0.04, Precision: 0.27, Recall: 0.99\nThreshold: 0.04, Precision: 0.27, Recall: 0.99\nThreshold: 0.04, Precision: 0.27, Recall: 0.99\nThreshold: 0.04, Precision: 0.27, Recall: 0.99\nThreshold: 0.04, Precision: 0.27, Recall: 0.99\nThreshold: 0.04, Precision: 0.27, Recall: 0.99\nThreshold: 0.04, Precision: 0.27, Recall: 0.99\nThreshold: 0.04, Precision: 0.27, Recall: 0.99\nThreshold: 0.04, Precision: 0.27, Recall: 0.99\nThreshold: 0.04, Precision: 0.27, Recall: 0.99\nThreshold: 0.04, Precision: 0.27, Recall: 0.99\nThreshold: 0.04, Precision: 0.27, Recall: 0.99\nThreshold: 0.04, Precision: 0.27, Recall: 0.99\nThreshold: 0.04, Precision: 0.27, Recall: 0.99\nThreshold: 0.04, Precision: 0.27, Recall: 0.99\nThreshold: 0.04, Precision: 0.27, Recall: 0.99\nThreshold: 0.04, Precision: 0.28, Recall: 0.99\nThreshold: 0.04, Precision: 0.28, Recall: 0.99\nThreshold: 0.04, Precision: 0.28, Recall: 0.99\nThreshold: 0.04, Precision: 0.28, Recall: 0.99\nThreshold: 0.04, Precision: 0.28, Recall: 0.99\nThreshold: 0.04, Precision: 0.28, Recall: 0.99\nThreshold: 0.04, Precision: 0.28, Recall: 0.99\nThreshold: 0.04, Precision: 0.28, Recall: 0.99\nThreshold: 0.04, Precision: 0.28, Recall: 0.99\nThreshold: 0.04, Precision: 0.28, Recall: 0.99\nThreshold: 0.04, Precision: 0.28, Recall: 0.99\nThreshold: 0.04, Precision: 0.28, Recall: 0.99\nThreshold: 0.04, Precision: 0.28, Recall: 0.99\nThreshold: 0.04, Precision: 0.28, Recall: 0.99\nThreshold: 0.04, Precision: 0.28, Recall: 0.99\nThreshold: 0.04, Precision: 0.28, Recall: 0.99\nThreshold: 0.04, Precision: 0.28, Recall: 0.99\nThreshold: 0.04, Precision: 0.28, Recall: 0.99\nThreshold: 0.04, Precision: 0.28, Recall: 0.99\nThreshold: 0.05, Precision: 0.28, Recall: 0.99\nThreshold: 0.05, Precision: 0.28, Recall: 0.99\nThreshold: 0.05, Precision: 0.28, Recall: 0.99\nThreshold: 0.05, Precision: 0.28, Recall: 0.99\nThreshold: 0.05, Precision: 0.28, Recall: 0.99\nThreshold: 0.05, Precision: 0.28, Recall: 0.99\nThreshold: 0.05, Precision: 0.28, Recall: 0.99\nThreshold: 0.05, Precision: 0.28, Recall: 0.99\nThreshold: 0.05, Precision: 0.28, Recall: 0.99\nThreshold: 0.05, Precision: 0.28, Recall: 0.99\nThreshold: 0.05, Precision: 0.28, Recall: 0.99\nThreshold: 0.05, Precision: 0.28, Recall: 0.99\nThreshold: 0.05, Precision: 0.28, Recall: 0.99\nThreshold: 0.05, Precision: 0.28, Recall: 0.99\nThreshold: 0.05, Precision: 0.28, Recall: 0.99\nThreshold: 0.05, Precision: 0.29, Recall: 0.99\nThreshold: 0.05, Precision: 0.29, Recall: 0.99\nThreshold: 0.05, Precision: 0.29, Recall: 0.99\nThreshold: 0.05, Precision: 0.29, Recall: 0.99\nThreshold: 0.05, Precision: 0.29, Recall: 0.99\nThreshold: 0.05, Precision: 0.29, Recall: 0.99\nThreshold: 0.05, Precision: 0.29, Recall: 0.99\nThreshold: 0.05, Precision: 0.29, Recall: 0.99\nThreshold: 0.05, Precision: 0.29, Recall: 0.99\nThreshold: 0.05, Precision: 0.29, Recall: 0.99\nThreshold: 0.05, Precision: 0.29, Recall: 0.99\nThreshold: 0.05, Precision: 0.29, Recall: 0.99\nThreshold: 0.05, Precision: 0.29, Recall: 0.99\nThreshold: 0.05, Precision: 0.29, Recall: 0.99\nThreshold: 0.05, Precision: 0.29, Recall: 0.99\nThreshold: 0.05, Precision: 0.29, Recall: 0.99\nThreshold: 0.05, Precision: 0.29, Recall: 0.99\nThreshold: 0.05, Precision: 0.29, Recall: 0.99\nThreshold: 0.05, Precision: 0.29, Recall: 0.99\nThreshold: 0.05, Precision: 0.29, Recall: 0.99\nThreshold: 0.05, Precision: 0.29, Recall: 0.99\nThreshold: 0.05, Precision: 0.29, Recall: 0.99\nThreshold: 0.05, Precision: 0.29, Recall: 0.99\nThreshold: 0.05, Precision: 0.29, Recall: 0.99\nThreshold: 0.05, Precision: 0.29, Recall: 0.99\nThreshold: 0.05, Precision: 0.29, Recall: 0.99\nThreshold: 0.05, Precision: 0.29, Recall: 0.99\nThreshold: 0.05, Precision: 0.29, Recall: 0.99\nThreshold: 0.05, Precision: 0.29, Recall: 0.99\nThreshold: 0.05, Precision: 0.29, Recall: 0.99\nThreshold: 0.05, Precision: 0.29, Recall: 0.99\nThreshold: 0.05, Precision: 0.29, Recall: 0.99\nThreshold: 0.05, Precision: 0.29, Recall: 0.99\nThreshold: 0.05, Precision: 0.29, Recall: 0.99\nThreshold: 0.06, Precision: 0.29, Recall: 0.99\nThreshold: 0.06, Precision: 0.29, Recall: 0.99\nThreshold: 0.06, Precision: 0.29, Recall: 0.99\nThreshold: 0.06, Precision: 0.29, Recall: 0.99\nThreshold: 0.06, Precision: 0.29, Recall: 0.99\nThreshold: 0.06, Precision: 0.30, Recall: 0.99\nThreshold: 0.06, Precision: 0.30, Recall: 0.99\nThreshold: 0.06, Precision: 0.30, Recall: 0.99\nThreshold: 0.06, Precision: 0.30, Recall: 0.99\nThreshold: 0.06, Precision: 0.30, Recall: 0.99\nThreshold: 0.06, Precision: 0.30, Recall: 0.99\nThreshold: 0.06, Precision: 0.30, Recall: 0.99\nThreshold: 0.06, Precision: 0.30, Recall: 0.99\nThreshold: 0.06, Precision: 0.30, Recall: 0.99\nThreshold: 0.06, Precision: 0.30, Recall: 0.99\nThreshold: 0.06, Precision: 0.30, Recall: 0.99\nThreshold: 0.06, Precision: 0.30, Recall: 0.99\nThreshold: 0.06, Precision: 0.30, Recall: 0.99\nThreshold: 0.06, Precision: 0.30, Recall: 0.99\nThreshold: 0.06, Precision: 0.30, Recall: 0.99\nThreshold: 0.06, Precision: 0.30, Recall: 0.99\nThreshold: 0.06, Precision: 0.30, Recall: 0.99\nThreshold: 0.06, Precision: 0.30, Recall: 0.99\nThreshold: 0.06, Precision: 0.30, Recall: 0.99\nThreshold: 0.06, Precision: 0.30, Recall: 0.99\nThreshold: 0.06, Precision: 0.30, Recall: 0.99\nThreshold: 0.06, Precision: 0.30, Recall: 0.99\nThreshold: 0.06, Precision: 0.30, Recall: 0.99\nThreshold: 0.06, Precision: 0.30, Recall: 0.99\nThreshold: 0.06, Precision: 0.30, Recall: 0.99\nThreshold: 0.06, Precision: 0.30, Recall: 0.99\nThreshold: 0.06, Precision: 0.30, Recall: 0.99\nThreshold: 0.06, Precision: 0.30, Recall: 0.99\nThreshold: 0.06, Precision: 0.30, Recall: 0.99\nThreshold: 0.06, Precision: 0.30, Recall: 0.99\nThreshold: 0.06, Precision: 0.30, Recall: 0.99\nThreshold: 0.06, Precision: 0.30, Recall: 0.99\nThreshold: 0.06, Precision: 0.30, Recall: 0.99\nThreshold: 0.06, Precision: 0.30, Recall: 0.99\nThreshold: 0.06, Precision: 0.30, Recall: 0.99\nThreshold: 0.06, Precision: 0.31, Recall: 0.99\nThreshold: 0.06, Precision: 0.31, Recall: 0.99\nThreshold: 0.06, Precision: 0.31, Recall: 0.99\nThreshold: 0.06, Precision: 0.31, Recall: 0.99\nThreshold: 0.07, Precision: 0.31, Recall: 0.99\nThreshold: 0.07, Precision: 0.31, Recall: 0.99\nThreshold: 0.07, Precision: 0.31, Recall: 0.99\nThreshold: 0.07, Precision: 0.31, Recall: 0.99\nThreshold: 0.07, Precision: 0.31, Recall: 0.99\nThreshold: 0.07, Precision: 0.31, Recall: 0.99\nThreshold: 0.07, Precision: 0.31, Recall: 0.99\nThreshold: 0.07, Precision: 0.31, Recall: 0.99\nThreshold: 0.07, Precision: 0.31, Recall: 0.99\nThreshold: 0.07, Precision: 0.31, Recall: 0.99\nThreshold: 0.07, Precision: 0.31, Recall: 0.99\nThreshold: 0.07, Precision: 0.31, Recall: 0.99\nThreshold: 0.07, Precision: 0.31, Recall: 0.99\nThreshold: 0.07, Precision: 0.31, Recall: 0.99\nThreshold: 0.07, Precision: 0.31, Recall: 0.99\nThreshold: 0.07, Precision: 0.31, Recall: 0.99\nThreshold: 0.07, Precision: 0.31, Recall: 0.99\nThreshold: 0.07, Precision: 0.31, Recall: 0.99\nThreshold: 0.07, Precision: 0.31, Recall: 0.99\nThreshold: 0.07, Precision: 0.31, Recall: 0.99\nThreshold: 0.07, Precision: 0.31, Recall: 0.99\nThreshold: 0.07, Precision: 0.31, Recall: 0.99\nThreshold: 0.07, Precision: 0.31, Recall: 0.99\nThreshold: 0.07, Precision: 0.31, Recall: 0.99\nThreshold: 0.07, Precision: 0.31, Recall: 0.99\nThreshold: 0.07, Precision: 0.31, Recall: 0.99\nThreshold: 0.07, Precision: 0.31, Recall: 0.99\nThreshold: 0.07, Precision: 0.31, Recall: 0.99\nThreshold: 0.07, Precision: 0.31, Recall: 0.99\nThreshold: 0.07, Precision: 0.31, Recall: 0.99\nThreshold: 0.07, Precision: 0.31, Recall: 0.99\nThreshold: 0.07, Precision: 0.32, Recall: 0.99\nThreshold: 0.07, Precision: 0.32, Recall: 0.99\nThreshold: 0.07, Precision: 0.32, Recall: 0.99\nThreshold: 0.07, Precision: 0.32, Recall: 0.99\nThreshold: 0.07, Precision: 0.32, Recall: 0.99\nThreshold: 0.07, Precision: 0.32, Recall: 0.99\nThreshold: 0.07, Precision: 0.32, Recall: 0.99\nThreshold: 0.07, Precision: 0.32, Recall: 0.99\nThreshold: 0.07, Precision: 0.32, Recall: 0.99\nThreshold: 0.07, Precision: 0.32, Recall: 0.99\nThreshold: 0.07, Precision: 0.32, Recall: 0.99\nThreshold: 0.07, Precision: 0.32, Recall: 0.99\nThreshold: 0.07, Precision: 0.32, Recall: 0.99\nThreshold: 0.07, Precision: 0.32, Recall: 0.99\nThreshold: 0.07, Precision: 0.32, Recall: 0.99\nThreshold: 0.07, Precision: 0.32, Recall: 0.99\nThreshold: 0.07, Precision: 0.32, Recall: 0.98\nThreshold: 0.07, Precision: 0.32, Recall: 0.98\nThreshold: 0.08, Precision: 0.32, Recall: 0.98\nThreshold: 0.08, Precision: 0.32, Recall: 0.98\nThreshold: 0.08, Precision: 0.32, Recall: 0.98\nThreshold: 0.08, Precision: 0.32, Recall: 0.98\nThreshold: 0.08, Precision: 0.32, Recall: 0.98\nThreshold: 0.08, Precision: 0.32, Recall: 0.98\nThreshold: 0.08, Precision: 0.32, Recall: 0.98\nThreshold: 0.08, Precision: 0.32, Recall: 0.98\nThreshold: 0.08, Precision: 0.32, Recall: 0.98\nThreshold: 0.08, Precision: 0.32, Recall: 0.98\nThreshold: 0.08, Precision: 0.32, Recall: 0.98\nThreshold: 0.08, Precision: 0.32, Recall: 0.98\nThreshold: 0.08, Precision: 0.32, Recall: 0.98\nThreshold: 0.08, Precision: 0.32, Recall: 0.98\nThreshold: 0.08, Precision: 0.32, Recall: 0.98\nThreshold: 0.08, Precision: 0.32, Recall: 0.98\nThreshold: 0.08, Precision: 0.33, Recall: 0.98\nThreshold: 0.08, Precision: 0.33, Recall: 0.98\nThreshold: 0.08, Precision: 0.33, Recall: 0.98\nThreshold: 0.08, Precision: 0.33, Recall: 0.98\nThreshold: 0.08, Precision: 0.33, Recall: 0.98\nThreshold: 0.08, Precision: 0.33, Recall: 0.98\nThreshold: 0.08, Precision: 0.33, Recall: 0.98\nThreshold: 0.08, Precision: 0.33, Recall: 0.98\nThreshold: 0.08, Precision: 0.33, Recall: 0.98\nThreshold: 0.08, Precision: 0.33, Recall: 0.98\nThreshold: 0.08, Precision: 0.33, Recall: 0.98\nThreshold: 0.08, Precision: 0.33, Recall: 0.98\nThreshold: 0.08, Precision: 0.33, Recall: 0.98\nThreshold: 0.08, Precision: 0.33, Recall: 0.98\nThreshold: 0.08, Precision: 0.33, Recall: 0.98\nThreshold: 0.08, Precision: 0.33, Recall: 0.98\nThreshold: 0.08, Precision: 0.33, Recall: 0.98\nThreshold: 0.08, Precision: 0.33, Recall: 0.98\nThreshold: 0.08, Precision: 0.33, Recall: 0.98\nThreshold: 0.08, Precision: 0.33, Recall: 0.98\nThreshold: 0.08, Precision: 0.33, Recall: 0.98\nThreshold: 0.08, Precision: 0.33, Recall: 0.98\nThreshold: 0.08, Precision: 0.33, Recall: 0.98\nThreshold: 0.08, Precision: 0.33, Recall: 0.98\nThreshold: 0.08, Precision: 0.33, Recall: 0.98\nThreshold: 0.08, Precision: 0.33, Recall: 0.98\nThreshold: 0.08, Precision: 0.33, Recall: 0.98\nThreshold: 0.09, Precision: 0.33, Recall: 0.98\nThreshold: 0.09, Precision: 0.33, Recall: 0.98\nThreshold: 0.09, Precision: 0.33, Recall: 0.98\nThreshold: 0.09, Precision: 0.33, Recall: 0.98\nThreshold: 0.09, Precision: 0.33, Recall: 0.98\nThreshold: 0.09, Precision: 0.33, Recall: 0.98\nThreshold: 0.09, Precision: 0.33, Recall: 0.98\nThreshold: 0.09, Precision: 0.34, Recall: 0.98\nThreshold: 0.09, Precision: 0.34, Recall: 0.98\nThreshold: 0.09, Precision: 0.34, Recall: 0.98\nThreshold: 0.09, Precision: 0.34, Recall: 0.98\nThreshold: 0.09, Precision: 0.34, Recall: 0.98\nThreshold: 0.09, Precision: 0.34, Recall: 0.98\nThreshold: 0.09, Precision: 0.34, Recall: 0.98\nThreshold: 0.09, Precision: 0.34, Recall: 0.98\nThreshold: 0.09, Precision: 0.34, Recall: 0.98\nThreshold: 0.09, Precision: 0.34, Recall: 0.98\nThreshold: 0.09, Precision: 0.34, Recall: 0.98\nThreshold: 0.09, Precision: 0.34, Recall: 0.98\nThreshold: 0.09, Precision: 0.34, Recall: 0.98\nThreshold: 0.09, Precision: 0.34, Recall: 0.98\nThreshold: 0.09, Precision: 0.34, Recall: 0.98\nThreshold: 0.09, Precision: 0.34, Recall: 0.98\nThreshold: 0.09, Precision: 0.34, Recall: 0.98\nThreshold: 0.09, Precision: 0.34, Recall: 0.98\nThreshold: 0.09, Precision: 0.34, Recall: 0.98\nThreshold: 0.09, Precision: 0.34, Recall: 0.98\nThreshold: 0.09, Precision: 0.34, Recall: 0.98\nThreshold: 0.09, Precision: 0.34, Recall: 0.98\nThreshold: 0.09, Precision: 0.34, Recall: 0.98\nThreshold: 0.09, Precision: 0.34, Recall: 0.98\nThreshold: 0.09, Precision: 0.34, Recall: 0.98\nThreshold: 0.09, Precision: 0.34, Recall: 0.98\nThreshold: 0.09, Precision: 0.34, Recall: 0.98\nThreshold: 0.09, Precision: 0.34, Recall: 0.98\nThreshold: 0.09, Precision: 0.35, Recall: 0.98\nThreshold: 0.10, Precision: 0.35, Recall: 0.98\nThreshold: 0.10, Precision: 0.35, Recall: 0.98\nThreshold: 0.10, Precision: 0.35, Recall: 0.98\nThreshold: 0.10, Precision: 0.35, Recall: 0.98\nThreshold: 0.10, Precision: 0.35, Recall: 0.98\nThreshold: 0.10, Precision: 0.35, Recall: 0.98\nThreshold: 0.10, Precision: 0.35, Recall: 0.98\nThreshold: 0.10, Precision: 0.35, Recall: 0.98\nThreshold: 0.10, Precision: 0.35, Recall: 0.98\nThreshold: 0.10, Precision: 0.35, Recall: 0.98\nThreshold: 0.10, Precision: 0.35, Recall: 0.98\nThreshold: 0.10, Precision: 0.35, Recall: 0.98\nThreshold: 0.10, Precision: 0.35, Recall: 0.98\nThreshold: 0.10, Precision: 0.35, Recall: 0.98\nThreshold: 0.10, Precision: 0.35, Recall: 0.98\nThreshold: 0.10, Precision: 0.35, Recall: 0.98\nThreshold: 0.10, Precision: 0.35, Recall: 0.98\nThreshold: 0.10, Precision: 0.35, Recall: 0.98\nThreshold: 0.10, Precision: 0.35, Recall: 0.98\nThreshold: 0.10, Precision: 0.35, Recall: 0.98\nThreshold: 0.10, Precision: 0.35, Recall: 0.98\nThreshold: 0.10, Precision: 0.35, Recall: 0.98\nThreshold: 0.10, Precision: 0.35, Recall: 0.98\nThreshold: 0.10, Precision: 0.35, Recall: 0.98\nThreshold: 0.10, Precision: 0.35, Recall: 0.98\nThreshold: 0.10, Precision: 0.35, Recall: 0.98\nThreshold: 0.10, Precision: 0.35, Recall: 0.98\nThreshold: 0.10, Precision: 0.35, Recall: 0.98\nThreshold: 0.10, Precision: 0.35, Recall: 0.98\nThreshold: 0.10, Precision: 0.35, Recall: 0.98\nThreshold: 0.10, Precision: 0.35, Recall: 0.98\nThreshold: 0.10, Precision: 0.35, Recall: 0.97\nThreshold: 0.11, Precision: 0.35, Recall: 0.97\nThreshold: 0.11, Precision: 0.35, Recall: 0.97\nThreshold: 0.11, Precision: 0.35, Recall: 0.97\nThreshold: 0.11, Precision: 0.35, Recall: 0.97\nThreshold: 0.11, Precision: 0.35, Recall: 0.97\nThreshold: 0.11, Precision: 0.35, Recall: 0.97\nThreshold: 0.11, Precision: 0.35, Recall: 0.97\nThreshold: 0.11, Precision: 0.36, Recall: 0.97\nThreshold: 0.11, Precision: 0.36, Recall: 0.97\nThreshold: 0.11, Precision: 0.36, Recall: 0.97\nThreshold: 0.11, Precision: 0.36, Recall: 0.97\nThreshold: 0.11, Precision: 0.36, Recall: 0.97\nThreshold: 0.11, Precision: 0.36, Recall: 0.97\nThreshold: 0.11, Precision: 0.36, Recall: 0.97\nThreshold: 0.11, Precision: 0.36, Recall: 0.97\nThreshold: 0.11, Precision: 0.36, Recall: 0.97\nThreshold: 0.11, Precision: 0.36, Recall: 0.97\nThreshold: 0.11, Precision: 0.36, Recall: 0.97\nThreshold: 0.12, Precision: 0.36, Recall: 0.97\nThreshold: 0.12, Precision: 0.36, Recall: 0.97\nThreshold: 0.12, Precision: 0.36, Recall: 0.97\nThreshold: 0.12, Precision: 0.36, Recall: 0.97\nThreshold: 0.12, Precision: 0.36, Recall: 0.97\nThreshold: 0.12, Precision: 0.36, Recall: 0.97\nThreshold: 0.12, Precision: 0.36, Recall: 0.97\nThreshold: 0.12, Precision: 0.36, Recall: 0.97\nThreshold: 0.12, Precision: 0.36, Recall: 0.97\nThreshold: 0.12, Precision: 0.36, Recall: 0.97\nThreshold: 0.12, Precision: 0.36, Recall: 0.97\nThreshold: 0.12, Precision: 0.36, Recall: 0.97\nThreshold: 0.12, Precision: 0.36, Recall: 0.97\nThreshold: 0.12, Precision: 0.36, Recall: 0.97\nThreshold: 0.12, Precision: 0.36, Recall: 0.96\nThreshold: 0.13, Precision: 0.36, Recall: 0.96\nThreshold: 0.13, Precision: 0.36, Recall: 0.96\nThreshold: 0.13, Precision: 0.36, Recall: 0.96\nThreshold: 0.13, Precision: 0.36, Recall: 0.96\nThreshold: 0.13, Precision: 0.36, Recall: 0.96\nThreshold: 0.13, Precision: 0.36, Recall: 0.96\nThreshold: 0.13, Precision: 0.36, Recall: 0.96\nThreshold: 0.13, Precision: 0.36, Recall: 0.96\nThreshold: 0.13, Precision: 0.36, Recall: 0.96\nThreshold: 0.13, Precision: 0.36, Recall: 0.96\nThreshold: 0.13, Precision: 0.37, Recall: 0.96\nThreshold: 0.13, Precision: 0.37, Recall: 0.96\nThreshold: 0.13, Precision: 0.37, Recall: 0.96\nThreshold: 0.14, Precision: 0.37, Recall: 0.96\nThreshold: 0.14, Precision: 0.37, Recall: 0.96\nThreshold: 0.14, Precision: 0.37, Recall: 0.96\nThreshold: 0.14, Precision: 0.37, Recall: 0.96\nThreshold: 0.14, Precision: 0.37, Recall: 0.96\nThreshold: 0.14, Precision: 0.37, Recall: 0.96\nThreshold: 0.14, Precision: 0.37, Recall: 0.96\nThreshold: 0.14, Precision: 0.37, Recall: 0.96\nThreshold: 0.14, Precision: 0.37, Recall: 0.95\nThreshold: 0.14, Precision: 0.37, Recall: 0.95\nThreshold: 0.14, Precision: 0.37, Recall: 0.95\nThreshold: 0.14, Precision: 0.37, Recall: 0.95\nThreshold: 0.14, Precision: 0.37, Recall: 0.95\nThreshold: 0.14, Precision: 0.37, Recall: 0.95\nThreshold: 0.14, Precision: 0.37, Recall: 0.95\nThreshold: 0.14, Precision: 0.37, Recall: 0.95\nThreshold: 0.14, Precision: 0.37, Recall: 0.95\nThreshold: 0.15, Precision: 0.37, Recall: 0.95\nThreshold: 0.15, Precision: 0.37, Recall: 0.95\nThreshold: 0.15, Precision: 0.37, Recall: 0.95\nThreshold: 0.15, Precision: 0.37, Recall: 0.95\nThreshold: 0.15, Precision: 0.37, Recall: 0.95\nThreshold: 0.15, Precision: 0.37, Recall: 0.95\nThreshold: 0.15, Precision: 0.37, Recall: 0.95\nThreshold: 0.15, Precision: 0.37, Recall: 0.95\nThreshold: 0.15, Precision: 0.37, Recall: 0.95\nThreshold: 0.15, Precision: 0.37, Recall: 0.95\nThreshold: 0.15, Precision: 0.37, Recall: 0.95\nThreshold: 0.15, Precision: 0.37, Recall: 0.95\nThreshold: 0.15, Precision: 0.37, Recall: 0.95\nThreshold: 0.15, Precision: 0.37, Recall: 0.95\nThreshold: 0.15, Precision: 0.37, Recall: 0.95\nThreshold: 0.16, Precision: 0.37, Recall: 0.95\nThreshold: 0.16, Precision: 0.37, Recall: 0.95\nThreshold: 0.16, Precision: 0.38, Recall: 0.95\nThreshold: 0.16, Precision: 0.38, Recall: 0.95\nThreshold: 0.16, Precision: 0.38, Recall: 0.95\nThreshold: 0.16, Precision: 0.38, Recall: 0.95\nThreshold: 0.16, Precision: 0.38, Recall: 0.95\nThreshold: 0.16, Precision: 0.38, Recall: 0.95\nThreshold: 0.16, Precision: 0.38, Recall: 0.95\nThreshold: 0.16, Precision: 0.38, Recall: 0.95\nThreshold: 0.16, Precision: 0.38, Recall: 0.95\nThreshold: 0.16, Precision: 0.38, Recall: 0.95\nThreshold: 0.16, Precision: 0.38, Recall: 0.95\nThreshold: 0.16, Precision: 0.38, Recall: 0.95\nThreshold: 0.16, Precision: 0.38, Recall: 0.95\nThreshold: 0.16, Precision: 0.38, Recall: 0.95\nThreshold: 0.16, Precision: 0.38, Recall: 0.95\nThreshold: 0.16, Precision: 0.38, Recall: 0.95\nThreshold: 0.16, Precision: 0.38, Recall: 0.95\nThreshold: 0.16, Precision: 0.38, Recall: 0.95\nThreshold: 0.16, Precision: 0.38, Recall: 0.95\nThreshold: 0.16, Precision: 0.38, Recall: 0.95\nThreshold: 0.17, Precision: 0.38, Recall: 0.95\nThreshold: 0.17, Precision: 0.38, Recall: 0.95\nThreshold: 0.17, Precision: 0.38, Recall: 0.95\nThreshold: 0.17, Precision: 0.38, Recall: 0.95\nThreshold: 0.17, Precision: 0.38, Recall: 0.95\nThreshold: 0.17, Precision: 0.38, Recall: 0.95\nThreshold: 0.17, Precision: 0.38, Recall: 0.95\nThreshold: 0.17, Precision: 0.39, Recall: 0.95\nThreshold: 0.17, Precision: 0.39, Recall: 0.95\nThreshold: 0.17, Precision: 0.39, Recall: 0.95\nThreshold: 0.18, Precision: 0.39, Recall: 0.95\nThreshold: 0.18, Precision: 0.39, Recall: 0.95\nThreshold: 0.18, Precision: 0.39, Recall: 0.95\nThreshold: 0.18, Precision: 0.39, Recall: 0.95\nThreshold: 0.18, Precision: 0.39, Recall: 0.95\nThreshold: 0.18, Precision: 0.39, Recall: 0.95\nThreshold: 0.18, Precision: 0.39, Recall: 0.95\nThreshold: 0.18, Precision: 0.39, Recall: 0.95\nThreshold: 0.18, Precision: 0.39, Recall: 0.95\nThreshold: 0.18, Precision: 0.39, Recall: 0.95\nThreshold: 0.18, Precision: 0.39, Recall: 0.95\nThreshold: 0.18, Precision: 0.39, Recall: 0.95\nThreshold: 0.18, Precision: 0.39, Recall: 0.95\nThreshold: 0.18, Precision: 0.39, Recall: 0.95\nThreshold: 0.18, Precision: 0.39, Recall: 0.95\nThreshold: 0.19, Precision: 0.39, Recall: 0.95\nThreshold: 0.19, Precision: 0.39, Recall: 0.95\nThreshold: 0.19, Precision: 0.39, Recall: 0.95\nThreshold: 0.19, Precision: 0.39, Recall: 0.94\nThreshold: 0.19, Precision: 0.39, Recall: 0.94\nThreshold: 0.19, Precision: 0.39, Recall: 0.94\nThreshold: 0.19, Precision: 0.39, Recall: 0.94\nThreshold: 0.19, Precision: 0.39, Recall: 0.94\nThreshold: 0.19, Precision: 0.39, Recall: 0.94\nThreshold: 0.19, Precision: 0.39, Recall: 0.94\nThreshold: 0.19, Precision: 0.39, Recall: 0.94\nThreshold: 0.20, Precision: 0.39, Recall: 0.94\nThreshold: 0.20, Precision: 0.39, Recall: 0.94\nThreshold: 0.20, Precision: 0.40, Recall: 0.94\nThreshold: 0.20, Precision: 0.40, Recall: 0.94\nThreshold: 0.20, Precision: 0.40, Recall: 0.94\nThreshold: 0.20, Precision: 0.40, Recall: 0.94\nThreshold: 0.20, Precision: 0.40, Recall: 0.94\nThreshold: 0.20, Precision: 0.40, Recall: 0.94\nThreshold: 0.20, Precision: 0.40, Recall: 0.94\nThreshold: 0.20, Precision: 0.40, Recall: 0.94\nThreshold: 0.21, Precision: 0.40, Recall: 0.94\nThreshold: 0.21, Precision: 0.40, Recall: 0.94\nThreshold: 0.21, Precision: 0.40, Recall: 0.94\nThreshold: 0.21, Precision: 0.40, Recall: 0.94\nThreshold: 0.21, Precision: 0.40, Recall: 0.94\nThreshold: 0.21, Precision: 0.40, Recall: 0.94\nThreshold: 0.21, Precision: 0.40, Recall: 0.94\nThreshold: 0.21, Precision: 0.40, Recall: 0.94\nThreshold: 0.21, Precision: 0.40, Recall: 0.94\nThreshold: 0.21, Precision: 0.40, Recall: 0.94\nThreshold: 0.21, Precision: 0.40, Recall: 0.94\nThreshold: 0.21, Precision: 0.40, Recall: 0.94\nThreshold: 0.22, Precision: 0.40, Recall: 0.94\nThreshold: 0.22, Precision: 0.40, Recall: 0.94\nThreshold: 0.22, Precision: 0.41, Recall: 0.94\nThreshold: 0.22, Precision: 0.41, Recall: 0.94\nThreshold: 0.22, Precision: 0.41, Recall: 0.94\nThreshold: 0.22, Precision: 0.41, Recall: 0.94\nThreshold: 0.22, Precision: 0.41, Recall: 0.94\nThreshold: 0.23, Precision: 0.41, Recall: 0.94\nThreshold: 0.23, Precision: 0.41, Recall: 0.94\nThreshold: 0.23, Precision: 0.41, Recall: 0.94\nThreshold: 0.23, Precision: 0.41, Recall: 0.94\nThreshold: 0.23, Precision: 0.41, Recall: 0.94\nThreshold: 0.23, Precision: 0.41, Recall: 0.94\nThreshold: 0.23, Precision: 0.41, Recall: 0.94\nThreshold: 0.23, Precision: 0.41, Recall: 0.94\nThreshold: 0.23, Precision: 0.41, Recall: 0.94\nThreshold: 0.23, Precision: 0.41, Recall: 0.94\nThreshold: 0.23, Precision: 0.41, Recall: 0.94\nThreshold: 0.23, Precision: 0.41, Recall: 0.94\nThreshold: 0.23, Precision: 0.41, Recall: 0.94\nThreshold: 0.23, Precision: 0.41, Recall: 0.94\nThreshold: 0.24, Precision: 0.41, Recall: 0.94\nThreshold: 0.24, Precision: 0.41, Recall: 0.94\nThreshold: 0.24, Precision: 0.41, Recall: 0.94\nThreshold: 0.24, Precision: 0.41, Recall: 0.94\nThreshold: 0.24, Precision: 0.42, Recall: 0.94\nThreshold: 0.24, Precision: 0.42, Recall: 0.94\nThreshold: 0.24, Precision: 0.42, Recall: 0.94\nThreshold: 0.24, Precision: 0.42, Recall: 0.94\nThreshold: 0.24, Precision: 0.42, Recall: 0.94\nThreshold: 0.25, Precision: 0.42, Recall: 0.94\nThreshold: 0.25, Precision: 0.42, Recall: 0.93\nThreshold: 0.25, Precision: 0.42, Recall: 0.93\nThreshold: 0.25, Precision: 0.42, Recall: 0.93\nThreshold: 0.25, Precision: 0.42, Recall: 0.93\nThreshold: 0.25, Precision: 0.42, Recall: 0.93\nThreshold: 0.25, Precision: 0.42, Recall: 0.93\nThreshold: 0.25, Precision: 0.42, Recall: 0.93\nThreshold: 0.25, Precision: 0.42, Recall: 0.93\nThreshold: 0.26, Precision: 0.42, Recall: 0.93\nThreshold: 0.26, Precision: 0.42, Recall: 0.93\nThreshold: 0.26, Precision: 0.42, Recall: 0.92\nThreshold: 0.26, Precision: 0.42, Recall: 0.92\nThreshold: 0.26, Precision: 0.42, Recall: 0.92\nThreshold: 0.26, Precision: 0.42, Recall: 0.92\nThreshold: 0.26, Precision: 0.42, Recall: 0.92\nThreshold: 0.26, Precision: 0.42, Recall: 0.92\nThreshold: 0.26, Precision: 0.42, Recall: 0.92\nThreshold: 0.26, Precision: 0.42, Recall: 0.91\nThreshold: 0.26, Precision: 0.42, Recall: 0.91\nThreshold: 0.27, Precision: 0.42, Recall: 0.91\nThreshold: 0.27, Precision: 0.42, Recall: 0.91\nThreshold: 0.27, Precision: 0.42, Recall: 0.91\nThreshold: 0.27, Precision: 0.42, Recall: 0.91\nThreshold: 0.27, Precision: 0.42, Recall: 0.91\nThreshold: 0.27, Precision: 0.42, Recall: 0.91\nThreshold: 0.27, Precision: 0.42, Recall: 0.91\nThreshold: 0.27, Precision: 0.42, Recall: 0.91\nThreshold: 0.27, Precision: 0.42, Recall: 0.91\nThreshold: 0.27, Precision: 0.42, Recall: 0.91\nThreshold: 0.27, Precision: 0.42, Recall: 0.91\nThreshold: 0.27, Precision: 0.42, Recall: 0.91\nThreshold: 0.27, Precision: 0.42, Recall: 0.91\nThreshold: 0.27, Precision: 0.42, Recall: 0.91\nThreshold: 0.27, Precision: 0.42, Recall: 0.91\nThreshold: 0.28, Precision: 0.42, Recall: 0.91\nThreshold: 0.28, Precision: 0.42, Recall: 0.91\nThreshold: 0.28, Precision: 0.42, Recall: 0.91\nThreshold: 0.28, Precision: 0.42, Recall: 0.90\nThreshold: 0.28, Precision: 0.42, Recall: 0.90\nThreshold: 0.28, Precision: 0.42, Recall: 0.90\nThreshold: 0.28, Precision: 0.42, Recall: 0.90\nThreshold: 0.28, Precision: 0.42, Recall: 0.90\nThreshold: 0.28, Precision: 0.42, Recall: 0.90\nThreshold: 0.28, Precision: 0.42, Recall: 0.90\nThreshold: 0.28, Precision: 0.42, Recall: 0.90\nThreshold: 0.28, Precision: 0.42, Recall: 0.90\nThreshold: 0.28, Precision: 0.42, Recall: 0.90\nThreshold: 0.28, Precision: 0.42, Recall: 0.90\nThreshold: 0.28, Precision: 0.42, Recall: 0.90\nThreshold: 0.29, Precision: 0.42, Recall: 0.90\nThreshold: 0.29, Precision: 0.42, Recall: 0.89\nThreshold: 0.29, Precision: 0.42, Recall: 0.89\nThreshold: 0.29, Precision: 0.42, Recall: 0.89\nThreshold: 0.29, Precision: 0.43, Recall: 0.89\nThreshold: 0.29, Precision: 0.43, Recall: 0.89\nThreshold: 0.29, Precision: 0.43, Recall: 0.89\nThreshold: 0.29, Precision: 0.43, Recall: 0.89\nThreshold: 0.29, Precision: 0.43, Recall: 0.89\nThreshold: 0.29, Precision: 0.43, Recall: 0.89\nThreshold: 0.29, Precision: 0.43, Recall: 0.89\nThreshold: 0.30, Precision: 0.43, Recall: 0.89\nThreshold: 0.30, Precision: 0.43, Recall: 0.89\nThreshold: 0.30, Precision: 0.43, Recall: 0.89\nThreshold: 0.30, Precision: 0.43, Recall: 0.89\nThreshold: 0.30, Precision: 0.43, Recall: 0.89\nThreshold: 0.30, Precision: 0.43, Recall: 0.89\nThreshold: 0.30, Precision: 0.43, Recall: 0.89\nThreshold: 0.30, Precision: 0.43, Recall: 0.89\nThreshold: 0.30, Precision: 0.43, Recall: 0.89\nThreshold: 0.30, Precision: 0.43, Recall: 0.89\nThreshold: 0.30, Precision: 0.43, Recall: 0.89\nThreshold: 0.30, Precision: 0.43, Recall: 0.89\nThreshold: 0.30, Precision: 0.43, Recall: 0.89\nThreshold: 0.31, Precision: 0.43, Recall: 0.88\nThreshold: 0.31, Precision: 0.43, Recall: 0.88\nThreshold: 0.31, Precision: 0.43, Recall: 0.88\nThreshold: 0.31, Precision: 0.43, Recall: 0.88\nThreshold: 0.31, Precision: 0.43, Recall: 0.88\nThreshold: 0.31, Precision: 0.43, Recall: 0.88\nThreshold: 0.31, Precision: 0.43, Recall: 0.88\nThreshold: 0.31, Precision: 0.43, Recall: 0.88\nThreshold: 0.31, Precision: 0.43, Recall: 0.88\nThreshold: 0.31, Precision: 0.43, Recall: 0.88\nThreshold: 0.31, Precision: 0.43, Recall: 0.88\nThreshold: 0.31, Precision: 0.44, Recall: 0.88\nThreshold: 0.31, Precision: 0.44, Recall: 0.88\nThreshold: 0.32, Precision: 0.44, Recall: 0.88\nThreshold: 0.32, Precision: 0.44, Recall: 0.87\nThreshold: 0.32, Precision: 0.44, Recall: 0.87\nThreshold: 0.32, Precision: 0.44, Recall: 0.87\nThreshold: 0.32, Precision: 0.44, Recall: 0.87\nThreshold: 0.32, Precision: 0.44, Recall: 0.87\nThreshold: 0.32, Precision: 0.44, Recall: 0.87\nThreshold: 0.32, Precision: 0.44, Recall: 0.87\nThreshold: 0.33, Precision: 0.44, Recall: 0.87\nThreshold: 0.33, Precision: 0.44, Recall: 0.87\nThreshold: 0.33, Precision: 0.44, Recall: 0.87\nThreshold: 0.33, Precision: 0.44, Recall: 0.87\nThreshold: 0.33, Precision: 0.44, Recall: 0.87\nThreshold: 0.33, Precision: 0.44, Recall: 0.87\nThreshold: 0.33, Precision: 0.44, Recall: 0.87\nThreshold: 0.34, Precision: 0.44, Recall: 0.87\nThreshold: 0.34, Precision: 0.44, Recall: 0.87\nThreshold: 0.34, Precision: 0.44, Recall: 0.87\nThreshold: 0.34, Precision: 0.44, Recall: 0.87\nThreshold: 0.34, Precision: 0.45, Recall: 0.87\nThreshold: 0.34, Precision: 0.44, Recall: 0.87\nThreshold: 0.34, Precision: 0.45, Recall: 0.87\nThreshold: 0.34, Precision: 0.45, Recall: 0.87\nThreshold: 0.34, Precision: 0.45, Recall: 0.87\nThreshold: 0.34, Precision: 0.45, Recall: 0.87\nThreshold: 0.34, Precision: 0.45, Recall: 0.87\nThreshold: 0.34, Precision: 0.45, Recall: 0.87\nThreshold: 0.35, Precision: 0.45, Recall: 0.87\nThreshold: 0.35, Precision: 0.45, Recall: 0.87\nThreshold: 0.35, Precision: 0.45, Recall: 0.87\nThreshold: 0.35, Precision: 0.45, Recall: 0.87\nThreshold: 0.35, Precision: 0.45, Recall: 0.87\nThreshold: 0.35, Precision: 0.45, Recall: 0.87\nThreshold: 0.35, Precision: 0.45, Recall: 0.87\nThreshold: 0.35, Precision: 0.45, Recall: 0.87\nThreshold: 0.36, Precision: 0.45, Recall: 0.87\nThreshold: 0.36, Precision: 0.45, Recall: 0.87\nThreshold: 0.36, Precision: 0.45, Recall: 0.87\nThreshold: 0.36, Precision: 0.46, Recall: 0.87\nThreshold: 0.36, Precision: 0.46, Recall: 0.87\nThreshold: 0.36, Precision: 0.46, Recall: 0.87\nThreshold: 0.36, Precision: 0.46, Recall: 0.87\nThreshold: 0.36, Precision: 0.46, Recall: 0.87\nThreshold: 0.36, Precision: 0.46, Recall: 0.87\nThreshold: 0.36, Precision: 0.46, Recall: 0.86\nThreshold: 0.37, Precision: 0.46, Recall: 0.86\nThreshold: 0.37, Precision: 0.46, Recall: 0.86\nThreshold: 0.37, Precision: 0.46, Recall: 0.86\nThreshold: 0.37, Precision: 0.46, Recall: 0.86\nThreshold: 0.37, Precision: 0.46, Recall: 0.86\nThreshold: 0.37, Precision: 0.46, Recall: 0.86\nThreshold: 0.37, Precision: 0.46, Recall: 0.86\nThreshold: 0.38, Precision: 0.46, Recall: 0.86\nThreshold: 0.38, Precision: 0.46, Recall: 0.86\nThreshold: 0.38, Precision: 0.46, Recall: 0.86\nThreshold: 0.38, Precision: 0.46, Recall: 0.86\nThreshold: 0.38, Precision: 0.46, Recall: 0.86\nThreshold: 0.38, Precision: 0.46, Recall: 0.85\nThreshold: 0.38, Precision: 0.46, Recall: 0.85\nThreshold: 0.38, Precision: 0.46, Recall: 0.85\nThreshold: 0.38, Precision: 0.46, Recall: 0.85\nThreshold: 0.38, Precision: 0.47, Recall: 0.85\nThreshold: 0.38, Precision: 0.47, Recall: 0.85\nThreshold: 0.38, Precision: 0.47, Recall: 0.85\nThreshold: 0.38, Precision: 0.47, Recall: 0.85\nThreshold: 0.38, Precision: 0.47, Recall: 0.85\nThreshold: 0.38, Precision: 0.47, Recall: 0.85\nThreshold: 0.38, Precision: 0.47, Recall: 0.85\nThreshold: 0.38, Precision: 0.47, Recall: 0.85\nThreshold: 0.39, Precision: 0.47, Recall: 0.85\nThreshold: 0.39, Precision: 0.47, Recall: 0.85\nThreshold: 0.39, Precision: 0.47, Recall: 0.85\nThreshold: 0.39, Precision: 0.47, Recall: 0.85\nThreshold: 0.39, Precision: 0.47, Recall: 0.85\nThreshold: 0.39, Precision: 0.47, Recall: 0.85\nThreshold: 0.39, Precision: 0.47, Recall: 0.85\nThreshold: 0.39, Precision: 0.47, Recall: 0.85\nThreshold: 0.39, Precision: 0.47, Recall: 0.85\nThreshold: 0.39, Precision: 0.47, Recall: 0.85\nThreshold: 0.39, Precision: 0.47, Recall: 0.84\nThreshold: 0.39, Precision: 0.47, Recall: 0.84\nThreshold: 0.39, Precision: 0.47, Recall: 0.84\nThreshold: 0.40, Precision: 0.47, Recall: 0.84\nThreshold: 0.40, Precision: 0.47, Recall: 0.84\nThreshold: 0.40, Precision: 0.47, Recall: 0.84\nThreshold: 0.40, Precision: 0.47, Recall: 0.84\nThreshold: 0.40, Precision: 0.47, Recall: 0.83\nThreshold: 0.40, Precision: 0.47, Recall: 0.83\nThreshold: 0.40, Precision: 0.47, Recall: 0.83\nThreshold: 0.40, Precision: 0.47, Recall: 0.83\nThreshold: 0.40, Precision: 0.47, Recall: 0.83\nThreshold: 0.41, Precision: 0.48, Recall: 0.83\nThreshold: 0.41, Precision: 0.48, Recall: 0.83\nThreshold: 0.41, Precision: 0.48, Recall: 0.83\nThreshold: 0.41, Precision: 0.48, Recall: 0.83\nThreshold: 0.41, Precision: 0.48, Recall: 0.83\nThreshold: 0.41, Precision: 0.48, Recall: 0.83\nThreshold: 0.41, Precision: 0.48, Recall: 0.83\nThreshold: 0.41, Precision: 0.48, Recall: 0.83\nThreshold: 0.42, Precision: 0.48, Recall: 0.83\nThreshold: 0.42, Precision: 0.48, Recall: 0.83\nThreshold: 0.42, Precision: 0.48, Recall: 0.83\nThreshold: 0.42, Precision: 0.48, Recall: 0.83\nThreshold: 0.42, Precision: 0.48, Recall: 0.83\nThreshold: 0.42, Precision: 0.48, Recall: 0.83\nThreshold: 0.42, Precision: 0.48, Recall: 0.82\nThreshold: 0.42, Precision: 0.48, Recall: 0.82\nThreshold: 0.42, Precision: 0.48, Recall: 0.82\nThreshold: 0.43, Precision: 0.48, Recall: 0.82\nThreshold: 0.43, Precision: 0.48, Recall: 0.82\nThreshold: 0.43, Precision: 0.48, Recall: 0.82\nThreshold: 0.43, Precision: 0.49, Recall: 0.82\nThreshold: 0.43, Precision: 0.48, Recall: 0.82\nThreshold: 0.43, Precision: 0.48, Recall: 0.82\nThreshold: 0.43, Precision: 0.48, Recall: 0.82\nThreshold: 0.43, Precision: 0.48, Recall: 0.82\nThreshold: 0.44, Precision: 0.48, Recall: 0.82\nThreshold: 0.44, Precision: 0.48, Recall: 0.81\nThreshold: 0.44, Precision: 0.48, Recall: 0.81\nThreshold: 0.44, Precision: 0.48, Recall: 0.81\nThreshold: 0.44, Precision: 0.49, Recall: 0.81\nThreshold: 0.44, Precision: 0.49, Recall: 0.81\nThreshold: 0.44, Precision: 0.49, Recall: 0.81\nThreshold: 0.44, Precision: 0.49, Recall: 0.81\nThreshold: 0.44, Precision: 0.49, Recall: 0.81\nThreshold: 0.44, Precision: 0.49, Recall: 0.81\nThreshold: 0.44, Precision: 0.49, Recall: 0.81\nThreshold: 0.44, Precision: 0.49, Recall: 0.81\nThreshold: 0.44, Precision: 0.49, Recall: 0.81\nThreshold: 0.44, Precision: 0.49, Recall: 0.81\nThreshold: 0.45, Precision: 0.49, Recall: 0.81\nThreshold: 0.45, Precision: 0.49, Recall: 0.81\nThreshold: 0.45, Precision: 0.49, Recall: 0.81\nThreshold: 0.45, Precision: 0.50, Recall: 0.81\nThreshold: 0.45, Precision: 0.50, Recall: 0.81\nThreshold: 0.45, Precision: 0.50, Recall: 0.81\nThreshold: 0.46, Precision: 0.50, Recall: 0.81\nThreshold: 0.46, Precision: 0.50, Recall: 0.80\nThreshold: 0.46, Precision: 0.49, Recall: 0.80\nThreshold: 0.46, Precision: 0.49, Recall: 0.80\nThreshold: 0.46, Precision: 0.50, Recall: 0.80\nThreshold: 0.46, Precision: 0.50, Recall: 0.80\nThreshold: 0.46, Precision: 0.50, Recall: 0.80\nThreshold: 0.46, Precision: 0.50, Recall: 0.80\nThreshold: 0.46, Precision: 0.50, Recall: 0.80\nThreshold: 0.46, Precision: 0.50, Recall: 0.80\nThreshold: 0.47, Precision: 0.50, Recall: 0.80\nThreshold: 0.47, Precision: 0.50, Recall: 0.80\nThreshold: 0.47, Precision: 0.50, Recall: 0.79\nThreshold: 0.47, Precision: 0.50, Recall: 0.79\nThreshold: 0.47, Precision: 0.50, Recall: 0.79\nThreshold: 0.47, Precision: 0.50, Recall: 0.79\nThreshold: 0.47, Precision: 0.50, Recall: 0.79\nThreshold: 0.47, Precision: 0.50, Recall: 0.79\nThreshold: 0.47, Precision: 0.50, Recall: 0.79\nThreshold: 0.48, Precision: 0.50, Recall: 0.79\nThreshold: 0.48, Precision: 0.50, Recall: 0.79\nThreshold: 0.48, Precision: 0.50, Recall: 0.79\nThreshold: 0.48, Precision: 0.50, Recall: 0.79\nThreshold: 0.48, Precision: 0.50, Recall: 0.79\nThreshold: 0.48, Precision: 0.50, Recall: 0.79\nThreshold: 0.48, Precision: 0.51, Recall: 0.79\nThreshold: 0.48, Precision: 0.51, Recall: 0.79\nThreshold: 0.48, Precision: 0.51, Recall: 0.79\nThreshold: 0.49, Precision: 0.51, Recall: 0.78\nThreshold: 0.49, Precision: 0.51, Recall: 0.78\nThreshold: 0.49, Precision: 0.51, Recall: 0.78\nThreshold: 0.49, Precision: 0.51, Recall: 0.78\nThreshold: 0.49, Precision: 0.51, Recall: 0.78\nThreshold: 0.49, Precision: 0.51, Recall: 0.78\nThreshold: 0.49, Precision: 0.51, Recall: 0.78\nThreshold: 0.49, Precision: 0.51, Recall: 0.78\nThreshold: 0.50, Precision: 0.51, Recall: 0.78\nThreshold: 0.50, Precision: 0.51, Recall: 0.78\nThreshold: 0.50, Precision: 0.51, Recall: 0.78\nThreshold: 0.50, Precision: 0.52, Recall: 0.78\nThreshold: 0.51, Precision: 0.51, Recall: 0.78\nThreshold: 0.51, Precision: 0.52, Recall: 0.78\nThreshold: 0.51, Precision: 0.52, Recall: 0.78\nThreshold: 0.51, Precision: 0.52, Recall: 0.78\nThreshold: 0.51, Precision: 0.52, Recall: 0.78\nThreshold: 0.51, Precision: 0.52, Recall: 0.78\nThreshold: 0.51, Precision: 0.51, Recall: 0.75\nThreshold: 0.51, Precision: 0.52, Recall: 0.75\nThreshold: 0.51, Precision: 0.52, Recall: 0.75\nThreshold: 0.51, Precision: 0.52, Recall: 0.75\nThreshold: 0.52, Precision: 0.52, Recall: 0.75\nThreshold: 0.52, Precision: 0.52, Recall: 0.75\nThreshold: 0.52, Precision: 0.52, Recall: 0.75\nThreshold: 0.52, Precision: 0.52, Recall: 0.74\nThreshold: 0.52, Precision: 0.51, Recall: 0.74\nThreshold: 0.52, Precision: 0.52, Recall: 0.74\nThreshold: 0.52, Precision: 0.51, Recall: 0.74\nThreshold: 0.52, Precision: 0.52, Recall: 0.74\nThreshold: 0.52, Precision: 0.52, Recall: 0.74\nThreshold: 0.52, Precision: 0.52, Recall: 0.74\nThreshold: 0.52, Precision: 0.52, Recall: 0.74\nThreshold: 0.52, Precision: 0.52, Recall: 0.74\nThreshold: 0.52, Precision: 0.52, Recall: 0.74\nThreshold: 0.53, Precision: 0.52, Recall: 0.74\nThreshold: 0.53, Precision: 0.52, Recall: 0.74\nThreshold: 0.53, Precision: 0.52, Recall: 0.74\nThreshold: 0.53, Precision: 0.52, Recall: 0.74\nThreshold: 0.53, Precision: 0.52, Recall: 0.74\nThreshold: 0.53, Precision: 0.52, Recall: 0.74\nThreshold: 0.53, Precision: 0.53, Recall: 0.74\nThreshold: 0.53, Precision: 0.53, Recall: 0.74\nThreshold: 0.53, Precision: 0.53, Recall: 0.74\nThreshold: 0.53, Precision: 0.53, Recall: 0.74\nThreshold: 0.53, Precision: 0.53, Recall: 0.74\nThreshold: 0.53, Precision: 0.54, Recall: 0.73\nThreshold: 0.54, Precision: 0.54, Recall: 0.73\nThreshold: 0.54, Precision: 0.54, Recall: 0.73\nThreshold: 0.54, Precision: 0.54, Recall: 0.73\nThreshold: 0.54, Precision: 0.54, Recall: 0.73\nThreshold: 0.54, Precision: 0.54, Recall: 0.73\nThreshold: 0.54, Precision: 0.54, Recall: 0.73\nThreshold: 0.54, Precision: 0.54, Recall: 0.73\nThreshold: 0.54, Precision: 0.54, Recall: 0.72\nThreshold: 0.55, Precision: 0.54, Recall: 0.72\nThreshold: 0.55, Precision: 0.54, Recall: 0.72\nThreshold: 0.55, Precision: 0.54, Recall: 0.72\nThreshold: 0.55, Precision: 0.54, Recall: 0.72\nThreshold: 0.55, Precision: 0.54, Recall: 0.72\nThreshold: 0.55, Precision: 0.54, Recall: 0.72\nThreshold: 0.55, Precision: 0.54, Recall: 0.72\nThreshold: 0.55, Precision: 0.54, Recall: 0.72\nThreshold: 0.55, Precision: 0.54, Recall: 0.72\nThreshold: 0.55, Precision: 0.54, Recall: 0.71\nThreshold: 0.55, Precision: 0.54, Recall: 0.71\nThreshold: 0.56, Precision: 0.54, Recall: 0.71\nThreshold: 0.56, Precision: 0.54, Recall: 0.71\nThreshold: 0.56, Precision: 0.54, Recall: 0.71\nThreshold: 0.56, Precision: 0.54, Recall: 0.71\nThreshold: 0.56, Precision: 0.55, Recall: 0.71\nThreshold: 0.56, Precision: 0.55, Recall: 0.71\nThreshold: 0.56, Precision: 0.55, Recall: 0.71\nThreshold: 0.56, Precision: 0.55, Recall: 0.71\nThreshold: 0.56, Precision: 0.55, Recall: 0.71\nThreshold: 0.57, Precision: 0.55, Recall: 0.71\nThreshold: 0.57, Precision: 0.55, Recall: 0.71\nThreshold: 0.57, Precision: 0.55, Recall: 0.71\nThreshold: 0.57, Precision: 0.55, Recall: 0.71\nThreshold: 0.57, Precision: 0.55, Recall: 0.71\nThreshold: 0.57, Precision: 0.55, Recall: 0.70\nThreshold: 0.57, Precision: 0.55, Recall: 0.70\nThreshold: 0.57, Precision: 0.55, Recall: 0.70\nThreshold: 0.57, Precision: 0.55, Recall: 0.70\nThreshold: 0.57, Precision: 0.55, Recall: 0.70\nThreshold: 0.58, Precision: 0.55, Recall: 0.70\nThreshold: 0.58, Precision: 0.56, Recall: 0.70\nThreshold: 0.58, Precision: 0.55, Recall: 0.70\nThreshold: 0.58, Precision: 0.56, Recall: 0.70\nThreshold: 0.58, Precision: 0.56, Recall: 0.70\nThreshold: 0.58, Precision: 0.56, Recall: 0.70\nThreshold: 0.58, Precision: 0.56, Recall: 0.69\nThreshold: 0.59, Precision: 0.56, Recall: 0.69\nThreshold: 0.59, Precision: 0.56, Recall: 0.69\nThreshold: 0.59, Precision: 0.56, Recall: 0.69\nThreshold: 0.59, Precision: 0.56, Recall: 0.69\nThreshold: 0.59, Precision: 0.56, Recall: 0.69\nThreshold: 0.59, Precision: 0.56, Recall: 0.69\nThreshold: 0.59, Precision: 0.56, Recall: 0.69\nThreshold: 0.59, Precision: 0.56, Recall: 0.68\nThreshold: 0.59, Precision: 0.56, Recall: 0.68\nThreshold: 0.59, Precision: 0.56, Recall: 0.68\nThreshold: 0.59, Precision: 0.56, Recall: 0.68\nThreshold: 0.59, Precision: 0.56, Recall: 0.68\nThreshold: 0.59, Precision: 0.56, Recall: 0.68\nThreshold: 0.59, Precision: 0.56, Recall: 0.67\nThreshold: 0.60, Precision: 0.56, Recall: 0.67\nThreshold: 0.60, Precision: 0.56, Recall: 0.67\nThreshold: 0.60, Precision: 0.56, Recall: 0.67\nThreshold: 0.60, Precision: 0.56, Recall: 0.67\nThreshold: 0.60, Precision: 0.56, Recall: 0.67\nThreshold: 0.60, Precision: 0.56, Recall: 0.67\nThreshold: 0.60, Precision: 0.56, Recall: 0.67\nThreshold: 0.60, Precision: 0.56, Recall: 0.67\nThreshold: 0.60, Precision: 0.57, Recall: 0.67\nThreshold: 0.60, Precision: 0.57, Recall: 0.67\nThreshold: 0.60, Precision: 0.57, Recall: 0.67\nThreshold: 0.60, Precision: 0.57, Recall: 0.67\nThreshold: 0.61, Precision: 0.57, Recall: 0.66\nThreshold: 0.61, Precision: 0.57, Recall: 0.66\nThreshold: 0.61, Precision: 0.57, Recall: 0.66\nThreshold: 0.61, Precision: 0.57, Recall: 0.66\nThreshold: 0.61, Precision: 0.57, Recall: 0.66\nThreshold: 0.61, Precision: 0.57, Recall: 0.66\nThreshold: 0.61, Precision: 0.57, Recall: 0.66\nThreshold: 0.61, Precision: 0.57, Recall: 0.65\nThreshold: 0.61, Precision: 0.57, Recall: 0.65\nThreshold: 0.61, Precision: 0.57, Recall: 0.65\nThreshold: 0.61, Precision: 0.57, Recall: 0.65\nThreshold: 0.61, Precision: 0.57, Recall: 0.65\nThreshold: 0.62, Precision: 0.57, Recall: 0.65\nThreshold: 0.62, Precision: 0.57, Recall: 0.65\nThreshold: 0.62, Precision: 0.57, Recall: 0.65\nThreshold: 0.62, Precision: 0.57, Recall: 0.65\nThreshold: 0.62, Precision: 0.57, Recall: 0.65\nThreshold: 0.62, Precision: 0.57, Recall: 0.64\nThreshold: 0.62, Precision: 0.57, Recall: 0.64\nThreshold: 0.62, Precision: 0.58, Recall: 0.64\nThreshold: 0.62, Precision: 0.58, Recall: 0.64\nThreshold: 0.62, Precision: 0.58, Recall: 0.64\nThreshold: 0.62, Precision: 0.58, Recall: 0.64\nThreshold: 0.62, Precision: 0.58, Recall: 0.64\nThreshold: 0.63, Precision: 0.58, Recall: 0.64\nThreshold: 0.63, Precision: 0.58, Recall: 0.64\nThreshold: 0.63, Precision: 0.58, Recall: 0.64\nThreshold: 0.63, Precision: 0.58, Recall: 0.64\nThreshold: 0.63, Precision: 0.58, Recall: 0.64\nThreshold: 0.63, Precision: 0.58, Recall: 0.63\nThreshold: 0.63, Precision: 0.58, Recall: 0.63\nThreshold: 0.63, Precision: 0.58, Recall: 0.63\nThreshold: 0.63, Precision: 0.58, Recall: 0.63\nThreshold: 0.63, Precision: 0.58, Recall: 0.63\nThreshold: 0.64, Precision: 0.58, Recall: 0.63\nThreshold: 0.64, Precision: 0.58, Recall: 0.63\nThreshold: 0.64, Precision: 0.58, Recall: 0.62\nThreshold: 0.64, Precision: 0.58, Recall: 0.62\nThreshold: 0.64, Precision: 0.58, Recall: 0.62\nThreshold: 0.64, Precision: 0.58, Recall: 0.62\nThreshold: 0.64, Precision: 0.58, Recall: 0.61\nThreshold: 0.64, Precision: 0.58, Recall: 0.61\nThreshold: 0.64, Precision: 0.58, Recall: 0.61\nThreshold: 0.64, Precision: 0.58, Recall: 0.61\nThreshold: 0.64, Precision: 0.58, Recall: 0.61\nThreshold: 0.64, Precision: 0.58, Recall: 0.61\nThreshold: 0.64, Precision: 0.58, Recall: 0.61\nThreshold: 0.64, Precision: 0.58, Recall: 0.61\nThreshold: 0.64, Precision: 0.58, Recall: 0.61\nThreshold: 0.65, Precision: 0.58, Recall: 0.60\nThreshold: 0.65, Precision: 0.58, Recall: 0.60\nThreshold: 0.65, Precision: 0.58, Recall: 0.60\nThreshold: 0.65, Precision: 0.59, Recall: 0.60\nThreshold: 0.65, Precision: 0.59, Recall: 0.60\nThreshold: 0.65, Precision: 0.59, Recall: 0.60\nThreshold: 0.65, Precision: 0.59, Recall: 0.60\nThreshold: 0.65, Precision: 0.59, Recall: 0.60\nThreshold: 0.65, Precision: 0.59, Recall: 0.60\nThreshold: 0.65, Precision: 0.59, Recall: 0.60\nThreshold: 0.65, Precision: 0.59, Recall: 0.60\nThreshold: 0.65, Precision: 0.59, Recall: 0.60\nThreshold: 0.65, Precision: 0.59, Recall: 0.59\nThreshold: 0.65, Precision: 0.59, Recall: 0.59\nThreshold: 0.66, Precision: 0.59, Recall: 0.59\nThreshold: 0.66, Precision: 0.59, Recall: 0.59\nThreshold: 0.66, Precision: 0.59, Recall: 0.59\nThreshold: 0.66, Precision: 0.59, Recall: 0.59\nThreshold: 0.66, Precision: 0.59, Recall: 0.59\nThreshold: 0.67, Precision: 0.59, Recall: 0.59\nThreshold: 0.67, Precision: 0.59, Recall: 0.59\nThreshold: 0.67, Precision: 0.60, Recall: 0.59\nThreshold: 0.67, Precision: 0.59, Recall: 0.58\nThreshold: 0.67, Precision: 0.59, Recall: 0.58\nThreshold: 0.67, Precision: 0.60, Recall: 0.58\nThreshold: 0.67, Precision: 0.60, Recall: 0.58\nThreshold: 0.67, Precision: 0.60, Recall: 0.58\nThreshold: 0.67, Precision: 0.60, Recall: 0.58\nThreshold: 0.67, Precision: 0.60, Recall: 0.58\nThreshold: 0.68, Precision: 0.60, Recall: 0.58\nThreshold: 0.68, Precision: 0.60, Recall: 0.58\nThreshold: 0.68, Precision: 0.61, Recall: 0.58\nThreshold: 0.68, Precision: 0.60, Recall: 0.57\nThreshold: 0.68, Precision: 0.60, Recall: 0.57\nThreshold: 0.68, Precision: 0.60, Recall: 0.57\nThreshold: 0.68, Precision: 0.61, Recall: 0.57\nThreshold: 0.68, Precision: 0.60, Recall: 0.57\nThreshold: 0.68, Precision: 0.61, Recall: 0.57\nThreshold: 0.68, Precision: 0.61, Recall: 0.57\nThreshold: 0.69, Precision: 0.61, Recall: 0.57\nThreshold: 0.69, Precision: 0.61, Recall: 0.56\nThreshold: 0.69, Precision: 0.61, Recall: 0.56\nThreshold: 0.69, Precision: 0.61, Recall: 0.56\nThreshold: 0.69, Precision: 0.61, Recall: 0.56\nThreshold: 0.69, Precision: 0.61, Recall: 0.56\nThreshold: 0.69, Precision: 0.61, Recall: 0.56\nThreshold: 0.69, Precision: 0.61, Recall: 0.56\nThreshold: 0.69, Precision: 0.61, Recall: 0.56\nThreshold: 0.69, Precision: 0.61, Recall: 0.56\nThreshold: 0.69, Precision: 0.62, Recall: 0.56\nThreshold: 0.69, Precision: 0.62, Recall: 0.56\nThreshold: 0.70, Precision: 0.62, Recall: 0.55\nThreshold: 0.70, Precision: 0.62, Recall: 0.55\nThreshold: 0.70, Precision: 0.62, Recall: 0.55\nThreshold: 0.70, Precision: 0.62, Recall: 0.55\nThreshold: 0.70, Precision: 0.62, Recall: 0.55\nThreshold: 0.70, Precision: 0.62, Recall: 0.55\nThreshold: 0.70, Precision: 0.62, Recall: 0.55\nThreshold: 0.70, Precision: 0.62, Recall: 0.55\nThreshold: 0.71, Precision: 0.62, Recall: 0.55\nThreshold: 0.71, Precision: 0.62, Recall: 0.55\nThreshold: 0.71, Precision: 0.63, Recall: 0.55\nThreshold: 0.71, Precision: 0.62, Recall: 0.54\nThreshold: 0.71, Precision: 0.62, Recall: 0.54\nThreshold: 0.71, Precision: 0.63, Recall: 0.54\nThreshold: 0.71, Precision: 0.62, Recall: 0.54\nThreshold: 0.71, Precision: 0.63, Recall: 0.54\nThreshold: 0.71, Precision: 0.63, Recall: 0.53\nThreshold: 0.72, Precision: 0.63, Recall: 0.53\nThreshold: 0.72, Precision: 0.63, Recall: 0.53\nThreshold: 0.72, Precision: 0.63, Recall: 0.53\nThreshold: 0.72, Precision: 0.63, Recall: 0.53\nThreshold: 0.72, Precision: 0.64, Recall: 0.53\nThreshold: 0.72, Precision: 0.64, Recall: 0.53\nThreshold: 0.72, Precision: 0.64, Recall: 0.53\nThreshold: 0.72, Precision: 0.64, Recall: 0.53\nThreshold: 0.72, Precision: 0.64, Recall: 0.53\nThreshold: 0.73, Precision: 0.64, Recall: 0.53\nThreshold: 0.73, Precision: 0.64, Recall: 0.53\nThreshold: 0.73, Precision: 0.65, Recall: 0.53\nThreshold: 0.73, Precision: 0.65, Recall: 0.53\nThreshold: 0.73, Precision: 0.65, Recall: 0.53\nThreshold: 0.73, Precision: 0.65, Recall: 0.52\nThreshold: 0.73, Precision: 0.65, Recall: 0.52\nThreshold: 0.73, Precision: 0.65, Recall: 0.52\nThreshold: 0.73, Precision: 0.65, Recall: 0.52\nThreshold: 0.73, Precision: 0.65, Recall: 0.52\nThreshold: 0.73, Precision: 0.65, Recall: 0.52\nThreshold: 0.73, Precision: 0.65, Recall: 0.52\nThreshold: 0.74, Precision: 0.65, Recall: 0.52\nThreshold: 0.74, Precision: 0.65, Recall: 0.51\nThreshold: 0.74, Precision: 0.65, Recall: 0.51\nThreshold: 0.74, Precision: 0.65, Recall: 0.51\nThreshold: 0.74, Precision: 0.65, Recall: 0.51\nThreshold: 0.74, Precision: 0.65, Recall: 0.51\nThreshold: 0.74, Precision: 0.65, Recall: 0.51\nThreshold: 0.74, Precision: 0.65, Recall: 0.51\nThreshold: 0.74, Precision: 0.66, Recall: 0.51\nThreshold: 0.75, Precision: 0.66, Recall: 0.50\nThreshold: 0.75, Precision: 0.66, Recall: 0.50\nThreshold: 0.75, Precision: 0.66, Recall: 0.50\nThreshold: 0.75, Precision: 0.66, Recall: 0.50\nThreshold: 0.75, Precision: 0.67, Recall: 0.50\nThreshold: 0.75, Precision: 0.66, Recall: 0.50\nThreshold: 0.75, Precision: 0.67, Recall: 0.49\nThreshold: 0.75, Precision: 0.66, Recall: 0.49\nThreshold: 0.75, Precision: 0.66, Recall: 0.49\nThreshold: 0.75, Precision: 0.66, Recall: 0.49\nThreshold: 0.75, Precision: 0.66, Recall: 0.48\nThreshold: 0.75, Precision: 0.66, Recall: 0.48\nThreshold: 0.76, Precision: 0.66, Recall: 0.48\nThreshold: 0.76, Precision: 0.66, Recall: 0.48\nThreshold: 0.76, Precision: 0.66, Recall: 0.48\nThreshold: 0.76, Precision: 0.66, Recall: 0.47\nThreshold: 0.76, Precision: 0.66, Recall: 0.47\nThreshold: 0.76, Precision: 0.66, Recall: 0.47\nThreshold: 0.76, Precision: 0.66, Recall: 0.47\nThreshold: 0.76, Precision: 0.66, Recall: 0.47\nThreshold: 0.76, Precision: 0.66, Recall: 0.46\nThreshold: 0.76, Precision: 0.65, Recall: 0.46\nThreshold: 0.76, Precision: 0.65, Recall: 0.46\nThreshold: 0.76, Precision: 0.66, Recall: 0.46\nThreshold: 0.76, Precision: 0.66, Recall: 0.46\nThreshold: 0.76, Precision: 0.66, Recall: 0.46\nThreshold: 0.76, Precision: 0.66, Recall: 0.45\nThreshold: 0.77, Precision: 0.66, Recall: 0.45\nThreshold: 0.77, Precision: 0.66, Recall: 0.45\nThreshold: 0.77, Precision: 0.66, Recall: 0.45\nThreshold: 0.77, Precision: 0.66, Recall: 0.45\nThreshold: 0.77, Precision: 0.67, Recall: 0.45\nThreshold: 0.77, Precision: 0.66, Recall: 0.44\nThreshold: 0.77, Precision: 0.66, Recall: 0.44\nThreshold: 0.77, Precision: 0.67, Recall: 0.44\nThreshold: 0.77, Precision: 0.66, Recall: 0.44\nThreshold: 0.77, Precision: 0.66, Recall: 0.44\nThreshold: 0.77, Precision: 0.66, Recall: 0.43\nThreshold: 0.77, Precision: 0.66, Recall: 0.43\nThreshold: 0.77, Precision: 0.66, Recall: 0.43\nThreshold: 0.77, Precision: 0.66, Recall: 0.43\nThreshold: 0.77, Precision: 0.66, Recall: 0.43\nThreshold: 0.78, Precision: 0.66, Recall: 0.42\nThreshold: 0.78, Precision: 0.66, Recall: 0.42\nThreshold: 0.78, Precision: 0.66, Recall: 0.42\nThreshold: 0.78, Precision: 0.65, Recall: 0.41\nThreshold: 0.78, Precision: 0.66, Recall: 0.41\nThreshold: 0.78, Precision: 0.66, Recall: 0.41\nThreshold: 0.78, Precision: 0.65, Recall: 0.41\nThreshold: 0.78, Precision: 0.66, Recall: 0.41\nThreshold: 0.78, Precision: 0.66, Recall: 0.41\nThreshold: 0.78, Precision: 0.66, Recall: 0.41\nThreshold: 0.78, Precision: 0.66, Recall: 0.40\nThreshold: 0.78, Precision: 0.66, Recall: 0.40\nThreshold: 0.79, Precision: 0.66, Recall: 0.40\nThreshold: 0.79, Precision: 0.66, Recall: 0.40\nThreshold: 0.79, Precision: 0.66, Recall: 0.40\nThreshold: 0.79, Precision: 0.66, Recall: 0.40\nThreshold: 0.79, Precision: 0.66, Recall: 0.40\nThreshold: 0.79, Precision: 0.66, Recall: 0.39\nThreshold: 0.79, Precision: 0.66, Recall: 0.39\nThreshold: 0.79, Precision: 0.67, Recall: 0.39\nThreshold: 0.79, Precision: 0.66, Recall: 0.39\nThreshold: 0.79, Precision: 0.67, Recall: 0.39\nThreshold: 0.79, Precision: 0.67, Recall: 0.39\nThreshold: 0.79, Precision: 0.67, Recall: 0.39\nThreshold: 0.79, Precision: 0.67, Recall: 0.39\nThreshold: 0.79, Precision: 0.67, Recall: 0.39\nThreshold: 0.79, Precision: 0.67, Recall: 0.38\nThreshold: 0.79, Precision: 0.67, Recall: 0.38\nThreshold: 0.79, Precision: 0.67, Recall: 0.38\nThreshold: 0.80, Precision: 0.67, Recall: 0.38\nThreshold: 0.80, Precision: 0.67, Recall: 0.37\nThreshold: 0.80, Precision: 0.67, Recall: 0.37\nThreshold: 0.80, Precision: 0.66, Recall: 0.37\nThreshold: 0.80, Precision: 0.67, Recall: 0.37\nThreshold: 0.80, Precision: 0.67, Recall: 0.37\nThreshold: 0.80, Precision: 0.67, Recall: 0.37\nThreshold: 0.80, Precision: 0.67, Recall: 0.37\nThreshold: 0.80, Precision: 0.67, Recall: 0.36\nThreshold: 0.80, Precision: 0.67, Recall: 0.36\nThreshold: 0.80, Precision: 0.67, Recall: 0.36\nThreshold: 0.80, Precision: 0.67, Recall: 0.36\nThreshold: 0.80, Precision: 0.67, Recall: 0.36\nThreshold: 0.80, Precision: 0.67, Recall: 0.36\nThreshold: 0.80, Precision: 0.68, Recall: 0.36\nThreshold: 0.80, Precision: 0.67, Recall: 0.35\nThreshold: 0.80, Precision: 0.67, Recall: 0.35\nThreshold: 0.80, Precision: 0.67, Recall: 0.35\nThreshold: 0.80, Precision: 0.67, Recall: 0.34\nThreshold: 0.80, Precision: 0.67, Recall: 0.34\nThreshold: 0.80, Precision: 0.68, Recall: 0.34\nThreshold: 0.80, Precision: 0.68, Recall: 0.34\nThreshold: 0.81, Precision: 0.68, Recall: 0.34\nThreshold: 0.81, Precision: 0.68, Recall: 0.34\nThreshold: 0.81, Precision: 0.68, Recall: 0.34\nThreshold: 0.81, Precision: 0.68, Recall: 0.34\nThreshold: 0.81, Precision: 0.68, Recall: 0.34\nThreshold: 0.81, Precision: 0.68, Recall: 0.33\nThreshold: 0.81, Precision: 0.69, Recall: 0.33\nThreshold: 0.81, Precision: 0.69, Recall: 0.33\nThreshold: 0.81, Precision: 0.69, Recall: 0.33\nThreshold: 0.81, Precision: 0.70, Recall: 0.33\nThreshold: 0.81, Precision: 0.70, Recall: 0.33\nThreshold: 0.81, Precision: 0.70, Recall: 0.33\nThreshold: 0.81, Precision: 0.70, Recall: 0.33\nThreshold: 0.81, Precision: 0.70, Recall: 0.33\nThreshold: 0.82, Precision: 0.71, Recall: 0.33\nThreshold: 0.82, Precision: 0.71, Recall: 0.33\nThreshold: 0.82, Precision: 0.71, Recall: 0.32\nThreshold: 0.82, Precision: 0.71, Recall: 0.32\nThreshold: 0.82, Precision: 0.71, Recall: 0.32\nThreshold: 0.82, Precision: 0.71, Recall: 0.32\nThreshold: 0.82, Precision: 0.71, Recall: 0.32\nThreshold: 0.82, Precision: 0.70, Recall: 0.31\nThreshold: 0.82, Precision: 0.71, Recall: 0.31\nThreshold: 0.82, Precision: 0.72, Recall: 0.31\nThreshold: 0.82, Precision: 0.72, Recall: 0.31\nThreshold: 0.82, Precision: 0.72, Recall: 0.31\nThreshold: 0.82, Precision: 0.72, Recall: 0.31\nThreshold: 0.82, Precision: 0.72, Recall: 0.30\nThreshold: 0.82, Precision: 0.72, Recall: 0.30\nThreshold: 0.82, Precision: 0.72, Recall: 0.30\nThreshold: 0.82, Precision: 0.72, Recall: 0.30\nThreshold: 0.83, Precision: 0.72, Recall: 0.30\nThreshold: 0.83, Precision: 0.72, Recall: 0.29\nThreshold: 0.83, Precision: 0.72, Recall: 0.29\nThreshold: 0.83, Precision: 0.73, Recall: 0.29\nThreshold: 0.83, Precision: 0.73, Recall: 0.29\nThreshold: 0.83, Precision: 0.72, Recall: 0.29\nThreshold: 0.83, Precision: 0.73, Recall: 0.29\nThreshold: 0.83, Precision: 0.73, Recall: 0.29\nThreshold: 0.83, Precision: 0.73, Recall: 0.29\nThreshold: 0.83, Precision: 0.73, Recall: 0.28\nThreshold: 0.83, Precision: 0.74, Recall: 0.28\nThreshold: 0.83, Precision: 0.74, Recall: 0.28\nThreshold: 0.83, Precision: 0.74, Recall: 0.28\nThreshold: 0.83, Precision: 0.74, Recall: 0.28\nThreshold: 0.83, Precision: 0.73, Recall: 0.27\nThreshold: 0.83, Precision: 0.73, Recall: 0.27\nThreshold: 0.83, Precision: 0.74, Recall: 0.27\nThreshold: 0.83, Precision: 0.74, Recall: 0.27\nThreshold: 0.84, Precision: 0.74, Recall: 0.27\nThreshold: 0.84, Precision: 0.74, Recall: 0.26\nThreshold: 0.84, Precision: 0.74, Recall: 0.26\nThreshold: 0.84, Precision: 0.75, Recall: 0.26\nThreshold: 0.84, Precision: 0.75, Recall: 0.26\nThreshold: 0.84, Precision: 0.74, Recall: 0.26\nThreshold: 0.84, Precision: 0.75, Recall: 0.26\nThreshold: 0.84, Precision: 0.76, Recall: 0.26\nThreshold: 0.84, Precision: 0.75, Recall: 0.25\nThreshold: 0.84, Precision: 0.76, Recall: 0.25\nThreshold: 0.84, Precision: 0.77, Recall: 0.25\nThreshold: 0.84, Precision: 0.77, Recall: 0.25\nThreshold: 0.84, Precision: 0.78, Recall: 0.25\nThreshold: 0.84, Precision: 0.78, Recall: 0.25\nThreshold: 0.84, Precision: 0.78, Recall: 0.25\nThreshold: 0.84, Precision: 0.77, Recall: 0.25\nThreshold: 0.84, Precision: 0.77, Recall: 0.24\nThreshold: 0.84, Precision: 0.77, Recall: 0.24\nThreshold: 0.84, Precision: 0.77, Recall: 0.24\nThreshold: 0.84, Precision: 0.77, Recall: 0.24\nThreshold: 0.84, Precision: 0.77, Recall: 0.24\nThreshold: 0.84, Precision: 0.77, Recall: 0.23\nThreshold: 0.85, Precision: 0.77, Recall: 0.23\nThreshold: 0.85, Precision: 0.77, Recall: 0.23\nThreshold: 0.85, Precision: 0.76, Recall: 0.22\nThreshold: 0.85, Precision: 0.76, Recall: 0.22\nThreshold: 0.85, Precision: 0.77, Recall: 0.22\nThreshold: 0.85, Precision: 0.77, Recall: 0.22\nThreshold: 0.85, Precision: 0.76, Recall: 0.22\nThreshold: 0.85, Precision: 0.77, Recall: 0.22\nThreshold: 0.85, Precision: 0.78, Recall: 0.22\nThreshold: 0.85, Precision: 0.78, Recall: 0.21\nThreshold: 0.85, Precision: 0.79, Recall: 0.21\nThreshold: 0.85, Precision: 0.79, Recall: 0.21\nThreshold: 0.85, Precision: 0.79, Recall: 0.21\nThreshold: 0.85, Precision: 0.79, Recall: 0.21\nThreshold: 0.85, Precision: 0.79, Recall: 0.21\nThreshold: 0.86, Precision: 0.80, Recall: 0.21\nThreshold: 0.86, Precision: 0.80, Recall: 0.20\nThreshold: 0.86, Precision: 0.80, Recall: 0.20\nThreshold: 0.86, Precision: 0.80, Recall: 0.20\nThreshold: 0.86, Precision: 0.79, Recall: 0.20\nThreshold: 0.86, Precision: 0.79, Recall: 0.19\nThreshold: 0.86, Precision: 0.79, Recall: 0.19\nThreshold: 0.86, Precision: 0.79, Recall: 0.19\nThreshold: 0.86, Precision: 0.78, Recall: 0.18\nThreshold: 0.86, Precision: 0.78, Recall: 0.18\nThreshold: 0.86, Precision: 0.79, Recall: 0.18\nThreshold: 0.86, Precision: 0.80, Recall: 0.18\nThreshold: 0.86, Precision: 0.81, Recall: 0.18\nThreshold: 0.86, Precision: 0.81, Recall: 0.18\nThreshold: 0.86, Precision: 0.80, Recall: 0.18\nThreshold: 0.86, Precision: 0.80, Recall: 0.17\nThreshold: 0.86, Precision: 0.81, Recall: 0.17\nThreshold: 0.86, Precision: 0.81, Recall: 0.17\nThreshold: 0.87, Precision: 0.81, Recall: 0.17\nThreshold: 0.87, Precision: 0.80, Recall: 0.16\nThreshold: 0.87, Precision: 0.80, Recall: 0.16\nThreshold: 0.87, Precision: 0.80, Recall: 0.16\nThreshold: 0.87, Precision: 0.79, Recall: 0.15\nThreshold: 0.87, Precision: 0.79, Recall: 0.15\nThreshold: 0.87, Precision: 0.79, Recall: 0.15\nThreshold: 0.87, Precision: 0.78, Recall: 0.14\nThreshold: 0.87, Precision: 0.77, Recall: 0.14\nThreshold: 0.87, Precision: 0.78, Recall: 0.14\nThreshold: 0.87, Precision: 0.80, Recall: 0.14\nThreshold: 0.88, Precision: 0.79, Recall: 0.13\nThreshold: 0.88, Precision: 0.79, Recall: 0.13\nThreshold: 0.88, Precision: 0.79, Recall: 0.13\nThreshold: 0.88, Precision: 0.78, Recall: 0.13\nThreshold: 0.88, Precision: 0.80, Recall: 0.13\nThreshold: 0.88, Precision: 0.79, Recall: 0.12\nThreshold: 0.88, Precision: 0.81, Recall: 0.12\nThreshold: 0.88, Precision: 0.80, Recall: 0.12\nThreshold: 0.88, Precision: 0.80, Recall: 0.11\nThreshold: 0.88, Precision: 0.79, Recall: 0.11\nThreshold: 0.88, Precision: 0.81, Recall: 0.11\nThreshold: 0.88, Precision: 0.82, Recall: 0.11\nThreshold: 0.88, Precision: 0.82, Recall: 0.11\nThreshold: 0.88, Precision: 0.82, Recall: 0.11\nThreshold: 0.88, Precision: 0.81, Recall: 0.10\nThreshold: 0.88, Precision: 0.83, Recall: 0.10\nThreshold: 0.88, Precision: 0.83, Recall: 0.10\nThreshold: 0.88, Precision: 0.82, Recall: 0.10\nThreshold: 0.88, Precision: 0.82, Recall: 0.10\nThreshold: 0.89, Precision: 0.81, Recall: 0.09\nThreshold: 0.89, Precision: 0.81, Recall: 0.09\nThreshold: 0.89, Precision: 0.80, Recall: 0.09\nThreshold: 0.89, Precision: 0.80, Recall: 0.09\nThreshold: 0.89, Precision: 0.79, Recall: 0.08\nThreshold: 0.89, Precision: 0.82, Recall: 0.08\nThreshold: 0.89, Precision: 0.81, Recall: 0.08\nThreshold: 0.89, Precision: 0.83, Recall: 0.08\nThreshold: 0.89, Precision: 0.83, Recall: 0.08\nThreshold: 0.89, Precision: 0.82, Recall: 0.07\nThreshold: 0.89, Precision: 0.82, Recall: 0.07\nThreshold: 0.89, Precision: 0.81, Recall: 0.07\nThreshold: 0.89, Precision: 0.81, Recall: 0.07\nThreshold: 0.89, Precision: 0.80, Recall: 0.06\nThreshold: 0.90, Precision: 0.79, Recall: 0.06\nThreshold: 0.90, Precision: 0.82, Recall: 0.06\nThreshold: 0.90, Precision: 0.81, Recall: 0.06\nThreshold: 0.90, Precision: 0.81, Recall: 0.06\nThreshold: 0.90, Precision: 0.80, Recall: 0.05\nThreshold: 0.90, Precision: 0.86, Recall: 0.05\nThreshold: 0.90, Precision: 0.85, Recall: 0.05\nThreshold: 0.90, Precision: 0.84, Recall: 0.04\nThreshold: 0.90, Precision: 0.83, Recall: 0.04\nThreshold: 0.90, Precision: 0.82, Recall: 0.04\nThreshold: 0.90, Precision: 0.80, Recall: 0.03\nThreshold: 0.91, Precision: 0.86, Recall: 0.03\nThreshold: 0.91, Precision: 0.83, Recall: 0.03\nThreshold: 0.91, Precision: 0.91, Recall: 0.03\nThreshold: 0.91, Precision: 1.00, Recall: 0.02\nThreshold: 0.92, Precision: 1.00, Recall: 0.02\nThreshold: 0.92, Precision: 1.00, Recall: 0.01\nThreshold: 0.93, Precision: 1.00, Recall: 0.01\nThreshold: 0.93, Precision: 1.00, Recall: 0.01\nThreshold: 0.93, Precision: 1.00, Recall: 0.00\nThreshold: 1.00, Precision: 1.00, Recall: 0.00\nClassification Report at threshold 0.6\n              precision    recall  f1-score   support\n\n           0       0.87      0.81      0.84      1033\n           1       0.56      0.67      0.61       374\n\n    accuracy                           0.77      1407\n   macro avg       0.72      0.74      0.72      1407\nweighted avg       0.79      0.77      0.78      1407\n\nConfusion Matrix:\n[[837 196]\n [124 250]]\nROC AUC Score: 0.8307289914117544\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"from catboost import CatBoostClassifier\nfrom sklearn.metrics import classification_report, roc_auc_score\n\n# Calculate class weights manually or use sklearn utility\nfrom sklearn.utils.class_weight import compute_class_weight\nimport numpy as np\n\nclasses = np.unique(y_train)\nclass_weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_train)\nclass_weights_dict = dict(zip(classes, class_weights))\n\nprint(\"Class weights:\", class_weights_dict)\n\n# Train CatBoost with class weights\nmodel = CatBoostClassifier(\n    iterations=1000,\n    depth=6,\n    learning_rate=0.05,\n    random_seed=42,\n    early_stopping_rounds=50,\n    class_weights=class_weights_dict,\n    verbose=100\n)\n\nmodel.fit(X_train, y_train, eval_set=(X_test, y_test), use_best_model=True)\n\n# Predict and evaluate\ny_pred = model.predict(X_test)\ny_proba = model.predict_proba(X_test)[:, 1]\n\nprint(classification_report(y_test, y_pred))\nprint(\"ROC AUC Score:\", roc_auc_score(y_test, y_proba))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T10:56:07.481957Z","iopub.execute_input":"2025-06-03T10:56:07.482778Z","iopub.status.idle":"2025-06-03T10:56:07.950031Z","shell.execute_reply.started":"2025-06-03T10:56:07.482742Z","shell.execute_reply":"2025-06-03T10:56:07.949112Z"}},"outputs":[{"name":"stdout","text":"Class weights: {0: 0.6809927360774818, 1: 1.8812709030100334}\n0:\tlearn: 0.6701641\ttest: 0.6714983\tbest: 0.6714983 (0)\ttotal: 5.78ms\tremaining: 5.78s\n100:\tlearn: 0.4316393\ttest: 0.4952457\tbest: 0.4927690 (61)\ttotal: 333ms\tremaining: 2.97s\nStopped by overfitting detector  (50 iterations wait)\n\nbestTest = 0.4927689809\nbestIteration = 61\n\nShrink model to first 62 iterations.\n              precision    recall  f1-score   support\n\n           0       0.91      0.70      0.79      1033\n           1       0.49      0.81      0.61       374\n\n    accuracy                           0.73      1407\n   macro avg       0.70      0.75      0.70      1407\nweighted avg       0.80      0.73      0.74      1407\n\nROC AUC Score: 0.8393327673408535\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"import numpy as np\n\nbest_acc = 0\nbest_thresh = 0.5\nfor thresh in np.arange(0.3, 0.8, 0.05):\n    preds = (y_proba >= thresh).astype(int)\n    acc = (preds == y_test).mean()\n    print(f\"Threshold: {thresh:.2f}, Accuracy: {acc:.4f}\")\n    if acc > best_acc:\n        best_acc = acc\n        best_thresh = thresh\n\nprint(f\"Best threshold: {best_thresh}, Best accuracy: {best_acc}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T10:56:35.238474Z","iopub.execute_input":"2025-06-03T10:56:35.238836Z","iopub.status.idle":"2025-06-03T10:56:35.248439Z","shell.execute_reply.started":"2025-06-03T10:56:35.238813Z","shell.execute_reply":"2025-06-03T10:56:35.247428Z"}},"outputs":[{"name":"stdout","text":"Threshold: 0.30, Accuracy: 0.6482\nThreshold: 0.35, Accuracy: 0.6759\nThreshold: 0.40, Accuracy: 0.6937\nThreshold: 0.45, Accuracy: 0.7107\nThreshold: 0.50, Accuracy: 0.7278\nThreshold: 0.55, Accuracy: 0.7569\nThreshold: 0.60, Accuracy: 0.7740\nThreshold: 0.65, Accuracy: 0.7875\nThreshold: 0.70, Accuracy: 0.7946\nThreshold: 0.75, Accuracy: 0.8017\nBest threshold: 0.7499999999999999, Best accuracy: 0.8017057569296375\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold\nfrom imblearn.over_sampling import SMOTE\nimport numpy as np\n\nskf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n\nauc_scores = []\naccuracy_scores = []\n\nfor fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n    X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n    X_val, y_val = X.iloc[val_idx], y.iloc[val_idx]\n\n    smote = SMOTE(random_state=42)\n    X_train_sm, y_train_sm = smote.fit_resample(X_train, y_train)\n\n    model = CatBoostClassifier(\n        iterations=2000,\n        depth=6,\n        learning_rate=0.03,\n        early_stopping_rounds=100,\n        random_seed=42,\n        verbose=100,\n        class_weights=class_weights_dict\n    )\n\n    model.fit(X_train_sm, y_train_sm, eval_set=(X_val, y_val), use_best_model=True)\n\n    y_val_proba = model.predict_proba(X_val)[:, 1]\n    \n    # Threshold tuning on validation fold (optional: optimize for accuracy)\n    best_acc = 0\n    best_thresh = 0.5\n    for thresh in np.arange(0.3, 0.8, 0.01):\n        y_pred_thresh = (y_val_proba >= thresh).astype(int)\n        acc = (y_pred_thresh == y_val).mean()\n        if acc > best_acc:\n            best_acc = acc\n            best_thresh = thresh\n    \n    print(f\"Fold {fold+1} best accuracy: {best_acc:.4f} at threshold {best_thresh:.2f}\")\n\n    auc_scores.append(roc_auc_score(y_val, y_val_proba))\n    accuracy_scores.append(best_acc)\n\nprint(f\"Mean ROC AUC: {np.mean(auc_scores):.4f}\")\nprint(f\"Mean Accuracy: {np.mean(accuracy_scores):.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T10:57:53.591422Z","iopub.execute_input":"2025-06-03T10:57:53.591823Z","iopub.status.idle":"2025-06-03T10:58:05.830264Z","shell.execute_reply.started":"2025-06-03T10:57:53.591797Z","shell.execute_reply":"2025-06-03T10:58:05.829279Z"}},"outputs":[{"name":"stdout","text":"0:\tlearn: 0.6740550\ttest: 0.6806303\tbest: 0.6806303 (0)\ttotal: 5.62ms\tremaining: 11.2s\n100:\tlearn: 0.3523330\ttest: 0.5307620\tbest: 0.5307620 (100)\ttotal: 425ms\tremaining: 7.99s\n200:\tlearn: 0.3232469\ttest: 0.5280801\tbest: 0.5277590 (197)\ttotal: 849ms\tremaining: 7.6s\n300:\tlearn: 0.3030292\ttest: 0.5253331\tbest: 0.5252942 (299)\ttotal: 1.27s\tremaining: 7.2s\n400:\tlearn: 0.2866385\ttest: 0.5226434\tbest: 0.5221248 (382)\ttotal: 1.7s\tremaining: 6.76s\n500:\tlearn: 0.2722479\ttest: 0.5212268\tbest: 0.5210792 (496)\ttotal: 2.12s\tremaining: 6.33s\n600:\tlearn: 0.2599712\ttest: 0.5204777\tbest: 0.5203882 (594)\ttotal: 2.54s\tremaining: 5.9s\n700:\tlearn: 0.2496122\ttest: 0.5205616\tbest: 0.5196581 (641)\ttotal: 2.96s\tremaining: 5.49s\nStopped by overfitting detector  (100 iterations wait)\n\nbestTest = 0.5196581209\nbestIteration = 641\n\nShrink model to first 642 iterations.\nFold 1 best accuracy: 0.7960 at threshold 0.79\n0:\tlearn: 0.6728463\ttest: 0.6798077\tbest: 0.6798077 (0)\ttotal: 4.67ms\tremaining: 9.33s\n100:\tlearn: 0.3505940\ttest: 0.5259091\tbest: 0.5257785 (87)\ttotal: 426ms\tremaining: 8.01s\n200:\tlearn: 0.3226482\ttest: 0.5199914\tbest: 0.5198801 (198)\ttotal: 850ms\tremaining: 7.6s\n300:\tlearn: 0.3027742\ttest: 0.5167754\tbest: 0.5166581 (296)\ttotal: 1.27s\tremaining: 7.17s\n400:\tlearn: 0.2853780\ttest: 0.5128572\tbest: 0.5128572 (400)\ttotal: 1.7s\tremaining: 6.76s\n500:\tlearn: 0.2715922\ttest: 0.5120450\tbest: 0.5118554 (497)\ttotal: 2.13s\tremaining: 6.38s\n600:\tlearn: 0.2593385\ttest: 0.5120479\tbest: 0.5118353 (588)\ttotal: 2.56s\tremaining: 5.96s\n700:\tlearn: 0.2493479\ttest: 0.5126927\tbest: 0.5117946 (608)\ttotal: 3s\tremaining: 5.57s\nStopped by overfitting detector  (100 iterations wait)\n\nbestTest = 0.5117946052\nbestIteration = 608\n\nShrink model to first 609 iterations.\nFold 2 best accuracy: 0.7868 at threshold 0.75\n0:\tlearn: 0.6726798\ttest: 0.6795675\tbest: 0.6795675 (0)\ttotal: 4.77ms\tremaining: 9.53s\n100:\tlearn: 0.3515501\ttest: 0.5401579\tbest: 0.5401579 (100)\ttotal: 444ms\tremaining: 8.35s\n200:\tlearn: 0.3219717\ttest: 0.5334886\tbest: 0.5334886 (200)\ttotal: 873ms\tremaining: 7.81s\n300:\tlearn: 0.3022325\ttest: 0.5300884\tbest: 0.5300884 (300)\ttotal: 1.3s\tremaining: 7.34s\n400:\tlearn: 0.2855945\ttest: 0.5279892\tbest: 0.5279892 (400)\ttotal: 1.73s\tremaining: 6.9s\n500:\tlearn: 0.2727158\ttest: 0.5270723\tbest: 0.5268296 (460)\ttotal: 2.2s\tremaining: 6.6s\n600:\tlearn: 0.2607896\ttest: 0.5255852\tbest: 0.5252874 (578)\ttotal: 2.63s\tremaining: 6.13s\nStopped by overfitting detector  (100 iterations wait)\n\nbestTest = 0.5252873833\nbestIteration = 578\n\nShrink model to first 579 iterations.\nFold 3 best accuracy: 0.7809 at threshold 0.79\n0:\tlearn: 0.6731053\ttest: 0.6806446\tbest: 0.6806446 (0)\ttotal: 4.55ms\tremaining: 9.1s\n100:\tlearn: 0.3536516\ttest: 0.5390843\tbest: 0.5386670 (78)\ttotal: 424ms\tremaining: 7.98s\n200:\tlearn: 0.3236407\ttest: 0.5364559\tbest: 0.5364559 (200)\ttotal: 848ms\tremaining: 7.59s\n300:\tlearn: 0.3023549\ttest: 0.5346419\tbest: 0.5343743 (261)\ttotal: 1.28s\tremaining: 7.21s\nStopped by overfitting detector  (100 iterations wait)\n\nbestTest = 0.5343743237\nbestIteration = 261\n\nShrink model to first 262 iterations.\nFold 4 best accuracy: 0.7845 at threshold 0.79\n0:\tlearn: 0.6738539\ttest: 0.6814126\tbest: 0.6814126 (0)\ttotal: 4.79ms\tremaining: 9.59s\n100:\tlearn: 0.3464405\ttest: 0.5434553\tbest: 0.5410474 (47)\ttotal: 444ms\tremaining: 8.35s\nStopped by overfitting detector  (100 iterations wait)\n\nbestTest = 0.5410473949\nbestIteration = 47\n\nShrink model to first 48 iterations.\nFold 5 best accuracy: 0.7937 at threshold 0.79\nMean ROC AUC: 0.8397\nMean Accuracy: 0.7884\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"from catboost import CatBoostClassifier\nfrom sklearn.metrics import classification_report, roc_auc_score\nimport numpy as np\n\n# Assuming X_train and X_test are pandas DataFrames\ncategorical_columns = X_train.select_dtypes(include=['object', 'category']).columns.tolist()\nprint(\"Categorical columns detected:\", categorical_columns)\ncat_features = [X_train.columns.get_loc(col) for col in categorical_columns]\n\n\n# Calculate class weights to handle imbalance\nfrom sklearn.utils.class_weight import compute_class_weight\n\nclasses = np.unique(y_train)\nclass_weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_train)\nclass_weights_dict = dict(zip(classes, class_weights))\nprint(\"Class weights:\", class_weights_dict)\n\n# Initialize CatBoost model with class weights and categorical features\nmodel = CatBoostClassifier(\n    iterations=1000,\n    depth=6,\n    learning_rate=0.05,\n    random_seed=42,\n    early_stopping_rounds=50,\n    class_weights=class_weights_dict,\n    cat_features=cat_features,\n    verbose=100\n)\n\n# Train model\nmodel.fit(X_train, y_train, eval_set=(X_test, y_test), use_best_model=True)\n\n# Predict and evaluate\ny_pred = model.predict(X_test)\ny_proba = model.predict_proba(X_test)[:, 1]\n\nprint(classification_report(y_test, y_pred))\nprint(\"ROC AUC Score:\", roc_auc_score(y_test, y_proba))\n\n# Find best threshold for accuracy\nbest_acc = 0\nbest_thresh = 0.5\nfor thresh in np.arange(0.3, 0.8, 0.05):\n    preds = (y_proba >= thresh).astype(int)\n    acc = (preds == y_test).mean()\n    print(f\"Threshold: {thresh:.2f}, Accuracy: {acc:.4f}\")\n    if acc > best_acc:\n        best_acc = acc\n        best_thresh = thresh\n\nprint(f\"Best threshold: {best_thresh}, Best accuracy: {best_acc}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T11:03:09.383131Z","iopub.execute_input":"2025-06-03T11:03:09.383469Z","iopub.status.idle":"2025-06-03T11:03:12.984111Z","shell.execute_reply.started":"2025-06-03T11:03:09.383444Z","shell.execute_reply":"2025-06-03T11:03:12.983224Z"}},"outputs":[{"name":"stdout","text":"Categorical columns detected: []\nClass weights: {0: 0.6809489227789881, 1: 1.8816053511705686}\n0:\tlearn: 0.6718266\ttest: 0.6726001\tbest: 0.6726001 (0)\ttotal: 4.52ms\tremaining: 4.51s\n100:\tlearn: 0.4308952\ttest: 0.4516201\tbest: 0.4516201 (100)\ttotal: 341ms\tremaining: 3.04s\n200:\tlearn: 0.3922528\ttest: 0.4194151\tbest: 0.4194151 (200)\ttotal: 673ms\tremaining: 2.68s\n300:\tlearn: 0.3594461\ttest: 0.3941970\tbest: 0.3941970 (300)\ttotal: 1s\tremaining: 2.33s\n400:\tlearn: 0.3323666\ttest: 0.3718854\tbest: 0.3718854 (400)\ttotal: 1.34s\tremaining: 2s\n500:\tlearn: 0.3077323\ttest: 0.3519274\tbest: 0.3519274 (500)\ttotal: 1.67s\tremaining: 1.66s\n600:\tlearn: 0.2870702\ttest: 0.3358558\tbest: 0.3358558 (600)\ttotal: 2s\tremaining: 1.33s\n700:\tlearn: 0.2690534\ttest: 0.3208904\tbest: 0.3208904 (700)\ttotal: 2.33s\tremaining: 996ms\n800:\tlearn: 0.2524343\ttest: 0.3077170\tbest: 0.3077170 (800)\ttotal: 2.67s\tremaining: 663ms\n900:\tlearn: 0.2368042\ttest: 0.2956269\tbest: 0.2956269 (900)\ttotal: 3.05s\tremaining: 335ms\n999:\tlearn: 0.2230378\ttest: 0.2842705\tbest: 0.2842705 (999)\ttotal: 3.38s\tremaining: 0us\n\nbestTest = 0.2842705422\nbestIteration = 999\n\n              precision    recall  f1-score   support\n\n           0       0.98      0.86      0.92      1033\n           1       0.72      0.95      0.82       374\n\n    accuracy                           0.89      1407\n   macro avg       0.85      0.91      0.87      1407\nweighted avg       0.91      0.89      0.89      1407\n\nROC AUC Score: 0.9570018273964519\nThreshold: 0.30, Accuracy: 0.8138\nThreshold: 0.35, Accuracy: 0.8365\nThreshold: 0.40, Accuracy: 0.8571\nThreshold: 0.45, Accuracy: 0.8721\nThreshold: 0.50, Accuracy: 0.8863\nThreshold: 0.55, Accuracy: 0.9026\nThreshold: 0.60, Accuracy: 0.9083\nThreshold: 0.65, Accuracy: 0.9055\nThreshold: 0.70, Accuracy: 0.9055\nThreshold: 0.75, Accuracy: 0.8991\nBest threshold: 0.5999999999999999, Best accuracy: 0.908315565031983\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"import optuna\nfrom catboost import CatBoostClassifier, Pool\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import accuracy_score\nimport numpy as np\n\n# Assuming X_train, y_train are your training data as pandas DataFrame/Series\n\ndef objective(trial):\n    params = {\n        'iterations': trial.suggest_int('iterations', 500, 1500),\n        'depth': trial.suggest_int('depth', 4, 10),\n        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n        'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1, 10),\n        'border_count': trial.suggest_int('border_count', 32, 255),\n        'random_strength': trial.suggest_float('random_strength', 1e-9, 10, log=True),\n        'bagging_temperature': trial.suggest_float('bagging_temperature', 0, 1),\n        'scale_pos_weight': trial.suggest_float('scale_pos_weight', 1, 5),\n        'verbose': 0,\n        'task_type': 'CPU'  # change to 'GPU' if you have GPU support\n    }\n\n    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n    accuracies = []\n\n    for train_idx, val_idx in skf.split(X_train, y_train):\n        X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n        y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n\n        train_pool = Pool(X_tr, y_tr, cat_features=cat_features)\n        val_pool = Pool(X_val, y_val, cat_features=cat_features)\n\n        model = CatBoostClassifier(**params)\n        model.fit(train_pool, eval_set=val_pool, early_stopping_rounds=50, use_best_model=True)\n\n        preds = model.predict(X_val)\n        acc = accuracy_score(y_val, preds)\n        accuracies.append(acc)\n\n    return np.mean(accuracies)\n\nstudy = optuna.create_study(direction='maximize')\nstudy.optimize(objective, n_trials=30)\n\nprint(f'Best trial accuracy: {study.best_value}')\nprint('Best hyperparameters:', study.best_params)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T11:05:48.425235Z","iopub.execute_input":"2025-06-03T11:05:48.426178Z","iopub.status.idle":"2025-06-03T11:08:14.017922Z","shell.execute_reply.started":"2025-06-03T11:05:48.426147Z","shell.execute_reply":"2025-06-03T11:08:14.016810Z"}},"outputs":[{"name":"stderr","text":"[I 2025-06-03 11:05:48,850] A new study created in memory with name: no-name-86cb16b6-c994-4dd8-9f7b-4db802e5fb25\n[I 2025-06-03 11:05:53,687] Trial 0 finished with value: 0.7817289915137162 and parameters: {'iterations': 772, 'depth': 9, 'learning_rate': 0.04383430566677442, 'l2_leaf_reg': 2.035100397551941, 'border_count': 46, 'random_strength': 2.5628985627947896e-05, 'bagging_temperature': 0.11996958739620422, 'scale_pos_weight': 1.9639792891171082}. Best is trial 0 with value: 0.7817289915137162.\n[I 2025-06-03 11:06:02,985] Trial 1 finished with value: 0.7827962897177818 and parameters: {'iterations': 1416, 'depth': 4, 'learning_rate': 0.012397072146621687, 'l2_leaf_reg': 9.521374031520919, 'border_count': 87, 'random_strength': 2.478978990240549, 'bagging_temperature': 0.7926572146488085, 'scale_pos_weight': 1.8505728643244965}. Best is trial 1 with value: 0.7827962897177818.\n[I 2025-06-03 11:06:05,916] Trial 2 finished with value: 0.7531138740872312 and parameters: {'iterations': 1202, 'depth': 8, 'learning_rate': 0.0986340129454838, 'l2_leaf_reg': 8.3116981977962, 'border_count': 200, 'random_strength': 0.05958758680943805, 'bagging_temperature': 0.5504833572928668, 'scale_pos_weight': 3.058766430402399}. Best is trial 1 with value: 0.7827962897177818.\n[I 2025-06-03 11:06:08,434] Trial 3 finished with value: 0.7433375172686008 and parameters: {'iterations': 1351, 'depth': 5, 'learning_rate': 0.029957834161439035, 'l2_leaf_reg': 7.46843669181668, 'border_count': 81, 'random_strength': 0.0007361776531906454, 'bagging_temperature': 0.14330328821835991, 'scale_pos_weight': 2.972703716105528}. Best is trial 1 with value: 0.7827962897177818.\n[I 2025-06-03 11:06:14,798] Trial 4 finished with value: 0.7522246694296427 and parameters: {'iterations': 605, 'depth': 6, 'learning_rate': 0.010675350834398559, 'l2_leaf_reg': 7.900672625926412, 'border_count': 145, 'random_strength': 1.3910226347691563e-09, 'bagging_temperature': 0.20177802950919133, 'scale_pos_weight': 2.7943563010046777}. Best is trial 1 with value: 0.7827962897177818.\n[I 2025-06-03 11:06:25,184] Trial 5 finished with value: 0.7372951253207027 and parameters: {'iterations': 784, 'depth': 9, 'learning_rate': 0.012879520209397574, 'l2_leaf_reg': 3.1773162739859044, 'border_count': 64, 'random_strength': 6.661653339498915e-08, 'bagging_temperature': 0.13670544330640633, 'scale_pos_weight': 3.8805706855953654}. Best is trial 1 with value: 0.7827962897177818.\n[I 2025-06-03 11:06:27,080] Trial 6 finished with value: 0.7038774817446221 and parameters: {'iterations': 1450, 'depth': 4, 'learning_rate': 0.05020093138952503, 'l2_leaf_reg': 9.268298019103511, 'border_count': 176, 'random_strength': 6.256961529131703e-05, 'bagging_temperature': 0.898580410744755, 'scale_pos_weight': 4.518147200846853}. Best is trial 1 with value: 0.7827962897177818.\n[I 2025-06-03 11:06:29,679] Trial 7 finished with value: 0.7406717979080324 and parameters: {'iterations': 1052, 'depth': 8, 'learning_rate': 0.065677926203464, 'l2_leaf_reg': 1.5169374431086515, 'border_count': 131, 'random_strength': 0.0009952051307716633, 'bagging_temperature': 0.9462825515309033, 'scale_pos_weight': 3.5950515795915043}. Best is trial 1 with value: 0.7827962897177818.\n[I 2025-06-03 11:06:42,778] Trial 8 finished with value: 0.7223649496743635 and parameters: {'iterations': 800, 'depth': 9, 'learning_rate': 0.012595341015314636, 'l2_leaf_reg': 8.240444747520316, 'border_count': 171, 'random_strength': 8.026405624686131e-06, 'bagging_temperature': 0.5693810067495939, 'scale_pos_weight': 4.460557912994695}. Best is trial 1 with value: 0.7827962897177818.\n[I 2025-06-03 11:06:45,534] Trial 9 finished with value: 0.7522237221235445 and parameters: {'iterations': 1312, 'depth': 9, 'learning_rate': 0.19934218398405848, 'l2_leaf_reg': 1.9745250477832608, 'border_count': 43, 'random_strength': 0.00031541460300074783, 'bagging_temperature': 0.8738512000081479, 'scale_pos_weight': 3.0924963143565174}. Best is trial 1 with value: 0.7827962897177818.\n[I 2025-06-03 11:06:52,437] Trial 10 finished with value: 0.7998605881192026 and parameters: {'iterations': 1084, 'depth': 4, 'learning_rate': 0.02291214067304016, 'l2_leaf_reg': 5.438070887961649, 'border_count': 236, 'random_strength': 8.88777473838222, 'bagging_temperature': 0.7032133901241363, 'scale_pos_weight': 1.3187276859978523}. Best is trial 10 with value: 0.7998605881192026.\n[I 2025-06-03 11:06:58,836] Trial 11 finished with value: 0.8023491612393923 and parameters: {'iterations': 1021, 'depth': 4, 'learning_rate': 0.023202957804763176, 'l2_leaf_reg': 5.387615432216718, 'border_count': 247, 'random_strength': 8.34103561088784, 'bagging_temperature': 0.6957273473000561, 'scale_pos_weight': 1.0811756532554366}. Best is trial 11 with value: 0.8023491612393923.\n[I 2025-06-03 11:07:04,165] Trial 12 finished with value: 0.8000377343595817 and parameters: {'iterations': 1075, 'depth': 6, 'learning_rate': 0.02601986577319833, 'l2_leaf_reg': 5.2182329113178, 'border_count': 247, 'random_strength': 9.255638423435808, 'bagging_temperature': 0.6915905332442356, 'scale_pos_weight': 1.1064901115001895}. Best is trial 11 with value: 0.8023491612393923.\n[I 2025-06-03 11:07:08,227] Trial 13 finished with value: 0.8030583777383067 and parameters: {'iterations': 959, 'depth': 6, 'learning_rate': 0.021457510984368627, 'l2_leaf_reg': 5.22059592791477, 'border_count': 254, 'random_strength': 0.1030713648684854, 'bagging_temperature': 0.6806930717905515, 'scale_pos_weight': 1.1178162436592376}. Best is trial 13 with value: 0.8030583777383067.\n[I 2025-06-03 11:07:12,173] Trial 14 finished with value: 0.7820851786066707 and parameters: {'iterations': 881, 'depth': 6, 'learning_rate': 0.021724020496272457, 'l2_leaf_reg': 4.313126345945178, 'border_count': 219, 'random_strength': 0.09985829640680956, 'bagging_temperature': 0.35028171158905996, 'scale_pos_weight': 1.87734673401932}. Best is trial 13 with value: 0.8030583777383067.\n[I 2025-06-03 11:07:16,413] Trial 15 finished with value: 0.7950605881192027 and parameters: {'iterations': 945, 'depth': 5, 'learning_rate': 0.01842543695992321, 'l2_leaf_reg': 6.6504188613146065, 'border_count': 254, 'random_strength': 0.07870517066254198, 'bagging_temperature': 0.4112861087472308, 'scale_pos_weight': 1.4853803107258046}. Best is trial 13 with value: 0.8030583777383067.\n[I 2025-06-03 11:07:19,144] Trial 16 finished with value: 0.7625327807381093 and parameters: {'iterations': 509, 'depth': 7, 'learning_rate': 0.03871707824114548, 'l2_leaf_reg': 4.06415804632878, 'border_count': 208, 'random_strength': 0.36957367628419185, 'bagging_temperature': 0.648572240349449, 'scale_pos_weight': 2.445930308895849}. Best is trial 13 with value: 0.8030583777383067.\n[I 2025-06-03 11:07:20,754] Trial 17 finished with value: 0.7660886520623642 and parameters: {'iterations': 1202, 'depth': 5, 'learning_rate': 0.10508847087278196, 'l2_leaf_reg': 6.535689104779291, 'border_count': 224, 'random_strength': 0.007426228765166768, 'bagging_temperature': 0.4280595199306143, 'scale_pos_weight': 2.32697861986597}. Best is trial 13 with value: 0.8030583777383067.\n[I 2025-06-03 11:07:26,632] Trial 18 finished with value: 0.8041244128675744 and parameters: {'iterations': 1189, 'depth': 7, 'learning_rate': 0.017476099215110168, 'l2_leaf_reg': 6.4366296961834175, 'border_count': 186, 'random_strength': 0.5424709214173834, 'bagging_temperature': 0.7862006739762851, 'scale_pos_weight': 1.0055524626334393}. Best is trial 18 with value: 0.8041244128675744.\n[I 2025-06-03 11:07:31,855] Trial 19 finished with value: 0.7929274126702192 and parameters: {'iterations': 1217, 'depth': 7, 'learning_rate': 0.01639111342276267, 'l2_leaf_reg': 6.480800337081875, 'border_count': 122, 'random_strength': 1.432022268239625e-06, 'bagging_temperature': 0.7645554627002138, 'scale_pos_weight': 1.5255641900400527}. Best is trial 18 with value: 0.8041244128675744.\n[I 2025-06-03 11:07:38,236] Trial 20 finished with value: 0.7762181961713045 and parameters: {'iterations': 927, 'depth': 10, 'learning_rate': 0.07368510104489052, 'l2_leaf_reg': 4.389091677196828, 'border_count': 183, 'random_strength': 0.012466668731324192, 'bagging_temperature': 0.008588270442773438, 'scale_pos_weight': 2.117174237417892}. Best is trial 18 with value: 0.8041244128675744.\n[I 2025-06-03 11:07:42,038] Trial 21 finished with value: 0.7961278863232681 and parameters: {'iterations': 1136, 'depth': 6, 'learning_rate': 0.033019905327206216, 'l2_leaf_reg': 5.912918485181178, 'border_count': 254, 'random_strength': 0.7271382924160333, 'bagging_temperature': 0.8081768880457776, 'scale_pos_weight': 1.474282146240844}. Best is trial 18 with value: 0.8041244128675744.\n[I 2025-06-03 11:07:47,884] Trial 22 finished with value: 0.8012810736135781 and parameters: {'iterations': 991, 'depth': 7, 'learning_rate': 0.01664426822406945, 'l2_leaf_reg': 3.05731657019684, 'border_count': 196, 'random_strength': 0.7830636574923653, 'bagging_temperature': 0.6169323296473516, 'scale_pos_weight': 1.0216655737092808}. Best is trial 18 with value: 0.8041244128675744.\n[I 2025-06-03 11:07:50,704] Trial 23 finished with value: 0.8030583777383067 and parameters: {'iterations': 1276, 'depth': 5, 'learning_rate': 0.02940974548778138, 'l2_leaf_reg': 5.0705051447251615, 'border_count': 231, 'random_strength': 0.00508025319514127, 'bagging_temperature': 0.7459699384801943, 'scale_pos_weight': 1.0725688662909916}. Best is trial 18 with value: 0.8041244128675744.\n[I 2025-06-03 11:07:53,210] Trial 24 finished with value: 0.7932835997631735 and parameters: {'iterations': 1307, 'depth': 5, 'learning_rate': 0.034544194413950464, 'l2_leaf_reg': 3.683920522433869, 'border_count': 226, 'random_strength': 0.0050470660671023005, 'bagging_temperature': 0.9986262842414309, 'scale_pos_weight': 1.601474991868578}. Best is trial 18 with value: 0.8041244128675744.\n[I 2025-06-03 11:07:55,178] Trial 25 finished with value: 0.7995040852575489 and parameters: {'iterations': 1266, 'depth': 8, 'learning_rate': 0.28928021590927416, 'l2_leaf_reg': 4.8714518271895, 'border_count': 211, 'random_strength': 0.027357405905072213, 'bagging_temperature': 0.8512339768409669, 'scale_pos_weight': 1.2830707887890713}. Best is trial 18 with value: 0.8041244128675744.\n[I 2025-06-03 11:07:59,384] Trial 26 finished with value: 0.7580900730215118 and parameters: {'iterations': 1161, 'depth': 6, 'learning_rate': 0.01730541492613275, 'l2_leaf_reg': 6.138271214703755, 'border_count': 158, 'random_strength': 0.0033108065736452068, 'bagging_temperature': 0.7439155047238316, 'scale_pos_weight': 2.521622974060648}. Best is trial 18 with value: 0.8041244128675744.\n[I 2025-06-03 11:08:07,690] Trial 27 finished with value: 0.788484389184922 and parameters: {'iterations': 1391, 'depth': 7, 'learning_rate': 0.010009915794628484, 'l2_leaf_reg': 6.8187386265072245, 'border_count': 232, 'random_strength': 0.19055064567344315, 'bagging_temperature': 0.4866128497448698, 'scale_pos_weight': 1.7234449557570712}. Best is trial 18 with value: 0.8041244128675744.\n[I 2025-06-03 11:08:10,993] Trial 28 finished with value: 0.7735538977698836 and parameters: {'iterations': 1140, 'depth': 5, 'learning_rate': 0.02703386132040127, 'l2_leaf_reg': 4.858915944149382, 'border_count': 195, 'random_strength': 1.2994133753222208, 'bagging_temperature': 0.601576908756917, 'scale_pos_weight': 2.170315578567477}. Best is trial 18 with value: 0.8041244128675744.\n[I 2025-06-03 11:08:14,012] Trial 29 finished with value: 0.805902348529702 and parameters: {'iterations': 677, 'depth': 7, 'learning_rate': 0.045060072209470614, 'l2_leaf_reg': 7.389161452084198, 'border_count': 237, 'random_strength': 1.1847226917286827e-05, 'bagging_temperature': 0.2913515511468162, 'scale_pos_weight': 1.0209249479944078}. Best is trial 29 with value: 0.805902348529702.\n","output_type":"stream"},{"name":"stdout","text":"Best trial accuracy: 0.805902348529702\nBest hyperparameters: {'iterations': 677, 'depth': 7, 'learning_rate': 0.045060072209470614, 'l2_leaf_reg': 7.389161452084198, 'border_count': 237, 'random_strength': 1.1847226917286827e-05, 'bagging_temperature': 0.2913515511468162, 'scale_pos_weight': 1.0209249479944078}\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"from sklearn.metrics import f1_score\n\ndef objective(trial):\n    params = {\n        'iterations': trial.suggest_int('iterations', 1000, 3000),\n        'depth': trial.suggest_int('depth', 6, 12),\n        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1, log=True),\n        'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1, 10),\n        'border_count': trial.suggest_int('border_count', 32, 255),\n        'random_strength': trial.suggest_float('random_strength', 1e-7, 10, log=True),\n        'bagging_temperature': trial.suggest_float('bagging_temperature', 0, 1),\n        'scale_pos_weight': trial.suggest_float('scale_pos_weight', 1, 5),\n        'verbose': 0,\n        'task_type': 'CPU'\n    }\n\n    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n    f1_scores = []\n\n    for train_idx, val_idx in skf.split(X_train, y_train):\n        X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n        y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n\n        train_pool = Pool(X_tr, y_tr, cat_features=cat_features)\n        val_pool = Pool(X_val, y_val, cat_features=cat_features)\n\n        model = CatBoostClassifier(**params)\n        model.fit(train_pool, eval_set=val_pool, early_stopping_rounds=100, use_best_model=True)\n\n        preds = model.predict(X_val)\n        f1 = f1_score(y_val, preds)\n        f1_scores.append(f1)\n\n    return np.mean(f1_scores)\n\nstudy = optuna.create_study(direction='maximize')\nstudy.optimize(objective, n_trials=40)\n\nprint(f'Best trial F1: {study.best_value}')\nprint('Best hyperparameters:', study.best_params)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T11:09:20.652506Z","iopub.execute_input":"2025-06-03T11:09:20.652878Z","iopub.status.idle":"2025-06-03T11:16:21.441822Z","shell.execute_reply.started":"2025-06-03T11:09:20.652851Z","shell.execute_reply":"2025-06-03T11:16:21.441057Z"}},"outputs":[{"name":"stderr","text":"[I 2025-06-03 11:09:20,659] A new study created in memory with name: no-name-e3e94a3a-203c-489b-bc9c-3c4e26263e98\n[I 2025-06-03 11:09:25,180] Trial 0 finished with value: 0.6296143526671731 and parameters: {'iterations': 1033, 'depth': 8, 'learning_rate': 0.05806867622357314, 'l2_leaf_reg': 3.5326129079349218, 'border_count': 205, 'random_strength': 0.00045528874039951046, 'bagging_temperature': 0.5655872245188747, 'scale_pos_weight': 3.2740686355148902}. Best is trial 0 with value: 0.6296143526671731.\n[I 2025-06-03 11:09:28,627] Trial 1 finished with value: 0.634482933882843 and parameters: {'iterations': 1285, 'depth': 7, 'learning_rate': 0.048666493456544495, 'l2_leaf_reg': 1.0446548841854737, 'border_count': 239, 'random_strength': 8.833426276597396e-07, 'bagging_temperature': 0.9530472206136087, 'scale_pos_weight': 2.5066635573783227}. Best is trial 1 with value: 0.634482933882843.\n[I 2025-06-03 11:09:32,085] Trial 2 finished with value: 0.6244570487161744 and parameters: {'iterations': 1643, 'depth': 6, 'learning_rate': 0.03360643400381581, 'l2_leaf_reg': 1.2056667050472158, 'border_count': 202, 'random_strength': 0.03708608971022045, 'bagging_temperature': 0.6705618062630831, 'scale_pos_weight': 3.839221448855735}. Best is trial 1 with value: 0.634482933882843.\n[I 2025-06-03 11:10:03,643] Trial 3 finished with value: 0.6302200774332329 and parameters: {'iterations': 1090, 'depth': 11, 'learning_rate': 0.012942245173201888, 'l2_leaf_reg': 1.4205821078344076, 'border_count': 90, 'random_strength': 0.0001297720991084594, 'bagging_temperature': 0.6837452501752446, 'scale_pos_weight': 3.5411680072755893}. Best is trial 1 with value: 0.634482933882843.\n[I 2025-06-03 11:10:33,557] Trial 4 finished with value: 0.608891877563275 and parameters: {'iterations': 2647, 'depth': 12, 'learning_rate': 0.028048778246253618, 'l2_leaf_reg': 9.936666308521353, 'border_count': 215, 'random_strength': 7.125195738124852, 'bagging_temperature': 0.09263070857355749, 'scale_pos_weight': 4.919238957802198}. Best is trial 1 with value: 0.634482933882843.\n[I 2025-06-03 11:10:38,712] Trial 5 finished with value: 0.6393589033436633 and parameters: {'iterations': 2550, 'depth': 9, 'learning_rate': 0.08681837153079544, 'l2_leaf_reg': 4.463582363041937, 'border_count': 41, 'random_strength': 6.06827524456507, 'bagging_temperature': 0.7579951420146809, 'scale_pos_weight': 2.1745072022925083}. Best is trial 5 with value: 0.6393589033436633.\n[I 2025-06-03 11:10:47,025] Trial 6 finished with value: 0.6374764133533243 and parameters: {'iterations': 2545, 'depth': 7, 'learning_rate': 0.011229719170174993, 'l2_leaf_reg': 7.83595274245501, 'border_count': 100, 'random_strength': 0.0021430551129910376, 'bagging_temperature': 0.6855078917048042, 'scale_pos_weight': 2.005762912035222}. Best is trial 5 with value: 0.6393589033436633.\n[I 2025-06-03 11:10:51,431] Trial 7 finished with value: 0.6152611364835567 and parameters: {'iterations': 1217, 'depth': 7, 'learning_rate': 0.02878282337523232, 'l2_leaf_reg': 7.752536341015552, 'border_count': 153, 'random_strength': 0.12727576959966663, 'bagging_temperature': 0.32441904951098666, 'scale_pos_weight': 4.6034620775593815}. Best is trial 5 with value: 0.6393589033436633.\n[I 2025-06-03 11:11:17,310] Trial 8 finished with value: 0.6245072661558961 and parameters: {'iterations': 2103, 'depth': 11, 'learning_rate': 0.020151104503643272, 'l2_leaf_reg': 4.685854157431974, 'border_count': 80, 'random_strength': 3.2465744009215975e-07, 'bagging_temperature': 0.6895203572457033, 'scale_pos_weight': 4.686484035748519}. Best is trial 5 with value: 0.6393589033436633.\n[I 2025-06-03 11:11:20,231] Trial 9 finished with value: 0.6339547426529648 and parameters: {'iterations': 1150, 'depth': 7, 'learning_rate': 0.09004946967273184, 'l2_leaf_reg': 7.165113363037596, 'border_count': 132, 'random_strength': 0.0002188123842889053, 'bagging_temperature': 0.48888664919511526, 'scale_pos_weight': 2.7257409568963764}. Best is trial 5 with value: 0.6393589033436633.\n[I 2025-06-03 11:11:25,769] Trial 10 finished with value: 0.596272401095814 and parameters: {'iterations': 2204, 'depth': 9, 'learning_rate': 0.09849040549571846, 'l2_leaf_reg': 3.655455559236955, 'border_count': 41, 'random_strength': 1.3194646441481361, 'bagging_temperature': 0.9809741632647782, 'scale_pos_weight': 1.175071212373196}. Best is trial 5 with value: 0.6393589033436633.\n[I 2025-06-03 11:11:41,447] Trial 11 finished with value: 0.6272656745773884 and parameters: {'iterations': 2973, 'depth': 9, 'learning_rate': 0.011114637725511736, 'l2_leaf_reg': 6.747695545462763, 'border_count': 37, 'random_strength': 0.014985655317749981, 'bagging_temperature': 0.8189647773233942, 'scale_pos_weight': 1.7828439812628951}. Best is trial 5 with value: 0.6393589033436633.\n[I 2025-06-03 11:11:59,661] Trial 12 finished with value: 0.6276960276942534 and parameters: {'iterations': 2516, 'depth': 10, 'learning_rate': 0.016958781468734575, 'l2_leaf_reg': 5.580425772386378, 'border_count': 89, 'random_strength': 3.6980783489802226e-05, 'bagging_temperature': 0.40814922587146896, 'scale_pos_weight': 2.0081010527031333}. Best is trial 5 with value: 0.6393589033436633.\n[I 2025-06-03 11:12:04,501] Trial 13 finished with value: 0.6035791063877491 and parameters: {'iterations': 2496, 'depth': 8, 'learning_rate': 0.06069460938793308, 'l2_leaf_reg': 9.04692510413914, 'border_count': 132, 'random_strength': 7.37538057163189e-06, 'bagging_temperature': 0.8257465690794598, 'scale_pos_weight': 1.0570979046250695}. Best is trial 5 with value: 0.6393589033436633.\n[I 2025-06-03 11:12:07,662] Trial 14 finished with value: 0.6353898623138956 and parameters: {'iterations': 2941, 'depth': 6, 'learning_rate': 0.043750083785591046, 'l2_leaf_reg': 5.643057996365739, 'border_count': 61, 'random_strength': 0.004416988665474477, 'bagging_temperature': 0.8119908231564423, 'scale_pos_weight': 2.002097050706889}. Best is trial 5 with value: 0.6393589033436633.\n[I 2025-06-03 11:12:15,616] Trial 15 finished with value: 0.629360090397592 and parameters: {'iterations': 1739, 'depth': 8, 'learning_rate': 0.01877407830554996, 'l2_leaf_reg': 8.502879798348074, 'border_count': 110, 'random_strength': 0.45635117947876824, 'bagging_temperature': 0.23507616418776345, 'scale_pos_weight': 1.606394386673167}. Best is trial 5 with value: 0.6393589033436633.\n[I 2025-06-03 11:12:21,935] Trial 16 finished with value: 0.636126104720501 and parameters: {'iterations': 2327, 'depth': 9, 'learning_rate': 0.07617382303364921, 'l2_leaf_reg': 3.227580034556272, 'border_count': 162, 'random_strength': 0.0036320862913233726, 'bagging_temperature': 0.57642084539937, 'scale_pos_weight': 2.4797445167444536}. Best is trial 5 with value: 0.6393589033436633.\n[I 2025-06-03 11:12:32,390] Trial 17 finished with value: 0.6355691965019279 and parameters: {'iterations': 2737, 'depth': 10, 'learning_rate': 0.03725932795082476, 'l2_leaf_reg': 6.377624312403734, 'border_count': 61, 'random_strength': 6.486312836073141, 'bagging_temperature': 0.7798224164885286, 'scale_pos_weight': 2.909392070890133}. Best is trial 5 with value: 0.6393589033436633.\n[I 2025-06-03 11:12:49,377] Trial 18 finished with value: 0.6196412974546534 and parameters: {'iterations': 2006, 'depth': 10, 'learning_rate': 0.022754780652197475, 'l2_leaf_reg': 4.534284740582648, 'border_count': 110, 'random_strength': 0.35466441928569936, 'bagging_temperature': 0.005668591642074006, 'scale_pos_weight': 1.4920541023174336}. Best is trial 5 with value: 0.6393589033436633.\n[I 2025-06-03 11:12:59,303] Trial 19 finished with value: 0.634030554585722 and parameters: {'iterations': 1842, 'depth': 8, 'learning_rate': 0.015207794240087988, 'l2_leaf_reg': 8.367965910455794, 'border_count': 179, 'random_strength': 5.73735624568277e-06, 'bagging_temperature': 0.9002968324834004, 'scale_pos_weight': 2.2850570407912203}. Best is trial 5 with value: 0.6393589033436633.\n[I 2025-06-03 11:13:06,245] Trial 20 finished with value: 0.6229469788516713 and parameters: {'iterations': 2321, 'depth': 6, 'learning_rate': 0.011103879399779946, 'l2_leaf_reg': 2.3333625990625073, 'border_count': 56, 'random_strength': 0.0022014571675346723, 'bagging_temperature': 0.5951392099390964, 'scale_pos_weight': 3.887390208938868}. Best is trial 5 with value: 0.6393589033436633.\n[I 2025-06-03 11:13:12,914] Trial 21 finished with value: 0.6366483880503258 and parameters: {'iterations': 2345, 'depth': 9, 'learning_rate': 0.07248256354714223, 'l2_leaf_reg': 3.2998231904091226, 'border_count': 172, 'random_strength': 0.006344784423742179, 'bagging_temperature': 0.48533238534566725, 'scale_pos_weight': 2.329400684207144}. Best is trial 5 with value: 0.6393589033436633.\n[I 2025-06-03 11:13:22,871] Trial 22 finished with value: 0.6303331985945604 and parameters: {'iterations': 2742, 'depth': 10, 'learning_rate': 0.07159378629552024, 'l2_leaf_reg': 4.441893802794812, 'border_count': 114, 'random_strength': 0.02610922065979272, 'bagging_temperature': 0.4565685116151713, 'scale_pos_weight': 2.188483443465727}. Best is trial 5 with value: 0.6393589033436633.\n[I 2025-06-03 11:13:29,028] Trial 23 finished with value: 0.6344463025153193 and parameters: {'iterations': 2487, 'depth': 9, 'learning_rate': 0.08207041162962808, 'l2_leaf_reg': 2.682834027819534, 'border_count': 177, 'random_strength': 3.084247944497965e-05, 'bagging_temperature': 0.3426820004963715, 'scale_pos_weight': 3.1336591374394485}. Best is trial 5 with value: 0.6393589033436633.\n[I 2025-06-03 11:13:32,469] Trial 24 finished with value: 0.6279356559261242 and parameters: {'iterations': 2290, 'depth': 7, 'learning_rate': 0.05743178295355627, 'l2_leaf_reg': 5.115360205676329, 'border_count': 178, 'random_strength': 0.001044790365463451, 'bagging_temperature': 0.7389057820431304, 'scale_pos_weight': 1.4478748008224194}. Best is trial 5 with value: 0.6393589033436633.\n[I 2025-06-03 11:13:52,088] Trial 25 finished with value: 0.630417753904225 and parameters: {'iterations': 2662, 'depth': 11, 'learning_rate': 0.04781092351917305, 'l2_leaf_reg': 6.032776513911389, 'border_count': 137, 'random_strength': 0.11713497480172834, 'bagging_temperature': 0.6039581541269999, 'scale_pos_weight': 2.682325653493513}. Best is trial 5 with value: 0.6393589033436633.\n[I 2025-06-03 11:13:56,310] Trial 26 finished with value: 0.6323289842891799 and parameters: {'iterations': 2427, 'depth': 8, 'learning_rate': 0.06922408729051668, 'l2_leaf_reg': 2.4496869513431, 'border_count': 251, 'random_strength': 1.3734379240947612, 'bagging_temperature': 0.8855414285503609, 'scale_pos_weight': 2.0819704457583006}. Best is trial 5 with value: 0.6393589033436633.\n[I 2025-06-03 11:14:51,456] Trial 27 finished with value: 0.6198628550429202 and parameters: {'iterations': 2858, 'depth': 12, 'learning_rate': 0.024267023589770877, 'l2_leaf_reg': 7.127507276514224, 'border_count': 68, 'random_strength': 0.007329189534443075, 'bagging_temperature': 0.5027541009413208, 'scale_pos_weight': 1.8146551869768266}. Best is trial 5 with value: 0.6393589033436633.\n[I 2025-06-03 11:14:57,230] Trial 28 finished with value: 0.6348838619018486 and parameters: {'iterations': 2110, 'depth': 9, 'learning_rate': 0.09976870192768005, 'l2_leaf_reg': 4.013919825820268, 'border_count': 103, 'random_strength': 0.0005769671539832861, 'bagging_temperature': 0.2571731142452248, 'scale_pos_weight': 2.3582181384119565}. Best is trial 5 with value: 0.6393589033436633.\n[I 2025-06-03 11:15:00,487] Trial 29 finished with value: 0.6333630395261256 and parameters: {'iterations': 2637, 'depth': 7, 'learning_rate': 0.05909159633298081, 'l2_leaf_reg': 3.0211370483384936, 'border_count': 201, 'random_strength': 0.0002571718608702858, 'bagging_temperature': 0.6497143941173675, 'scale_pos_weight': 3.4406952896760017}. Best is trial 5 with value: 0.6393589033436633.\n[I 2025-06-03 11:15:05,669] Trial 30 finished with value: 0.6340005425383601 and parameters: {'iterations': 1472, 'depth': 8, 'learning_rate': 0.03951795415003393, 'l2_leaf_reg': 3.952405800794015, 'border_count': 48, 'random_strength': 0.10594766867777378, 'bagging_temperature': 0.5183446066169273, 'scale_pos_weight': 2.887120364271117}. Best is trial 5 with value: 0.6393589033436633.\n[I 2025-06-03 11:15:11,889] Trial 31 finished with value: 0.6380549431652749 and parameters: {'iterations': 2314, 'depth': 9, 'learning_rate': 0.08052117120810398, 'l2_leaf_reg': 3.221483764512423, 'border_count': 149, 'random_strength': 0.0017192445925558017, 'bagging_temperature': 0.5396079587290404, 'scale_pos_weight': 2.488057988353752}. Best is trial 5 with value: 0.6393589033436633.\n[I 2025-06-03 11:15:21,920] Trial 32 finished with value: 0.6291011599641102 and parameters: {'iterations': 2396, 'depth': 10, 'learning_rate': 0.08244400578362722, 'l2_leaf_reg': 2.0583367446630323, 'border_count': 164, 'random_strength': 0.0013262518368913141, 'bagging_temperature': 0.73461011844437, 'scale_pos_weight': 2.5955740464168757}. Best is trial 5 with value: 0.6393589033436633.\n[I 2025-06-03 11:15:28,351] Trial 33 finished with value: 0.6243245140083502 and parameters: {'iterations': 2188, 'depth': 9, 'learning_rate': 0.06414137178036035, 'l2_leaf_reg': 5.054943027543202, 'border_count': 125, 'random_strength': 5.008207894241593e-05, 'bagging_temperature': 0.4204621655765613, 'scale_pos_weight': 1.7261962480296853}. Best is trial 5 with value: 0.6393589033436633.\n[I 2025-06-03 11:15:35,301] Trial 34 finished with value: 0.6304513774461613 and parameters: {'iterations': 2022, 'depth': 9, 'learning_rate': 0.04969797972736082, 'l2_leaf_reg': 1.7598440838237182, 'border_count': 146, 'random_strength': 0.01056336326759605, 'bagging_temperature': 0.54898576988033, 'scale_pos_weight': 2.2856585228602353}. Best is trial 5 with value: 0.6393589033436633.\n[I 2025-06-03 11:15:40,097] Trial 35 finished with value: 0.6308683303857812 and parameters: {'iterations': 1872, 'depth': 8, 'learning_rate': 0.05256371921000334, 'l2_leaf_reg': 3.25333553831993, 'border_count': 193, 'random_strength': 0.04001295313689395, 'bagging_temperature': 0.6354141834259884, 'scale_pos_weight': 3.034482302793509}. Best is trial 5 with value: 0.6393589033436633.\n[I 2025-06-03 11:15:42,615] Trial 36 finished with value: 0.6331893489913223 and parameters: {'iterations': 2571, 'depth': 6, 'learning_rate': 0.08424368762924216, 'l2_leaf_reg': 3.9216483878095687, 'border_count': 212, 'random_strength': 5.936518057527289e-06, 'bagging_temperature': 0.7127097875500474, 'scale_pos_weight': 1.9514630818246124}. Best is trial 5 with value: 0.6393589033436633.\n[I 2025-06-03 11:15:49,783] Trial 37 finished with value: 0.6358098967124872 and parameters: {'iterations': 2825, 'depth': 7, 'learning_rate': 0.013947086697652348, 'l2_leaf_reg': 2.973593130649566, 'border_count': 228, 'random_strength': 8.458046016107307e-05, 'bagging_temperature': 0.37739368972044907, 'scale_pos_weight': 2.505769337187761}. Best is trial 5 with value: 0.6393589033436633.\n[I 2025-06-03 11:16:09,371] Trial 38 finished with value: 0.6097812224565148 and parameters: {'iterations': 2222, 'depth': 11, 'learning_rate': 0.06696359042503712, 'l2_leaf_reg': 9.765699683874768, 'border_count': 82, 'random_strength': 0.0005323983224440095, 'bagging_temperature': 0.6381453812345146, 'scale_pos_weight': 1.3646091587077405}. Best is trial 5 with value: 0.6393589033436633.\n[I 2025-06-03 11:16:21,437] Trial 39 finished with value: 0.6279479021795342 and parameters: {'iterations': 2573, 'depth': 10, 'learning_rate': 0.03335920055821817, 'l2_leaf_reg': 1.2874301932936276, 'border_count': 149, 'random_strength': 1.7907523329092206e-06, 'bagging_temperature': 0.9059924438425535, 'scale_pos_weight': 4.026593852211803}. Best is trial 5 with value: 0.6393589033436633.\n","output_type":"stream"},{"name":"stdout","text":"Best trial F1: 0.6393589033436633\nBest hyperparameters: {'iterations': 2550, 'depth': 9, 'learning_rate': 0.08681837153079544, 'l2_leaf_reg': 4.463582363041937, 'border_count': 41, 'random_strength': 6.06827524456507, 'bagging_temperature': 0.7579951420146809, 'scale_pos_weight': 2.1745072022925083}\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"def objective(trial):\n    params = {\n        'iterations': trial.suggest_int('iterations', 1000, 2000),\n        'depth': trial.suggest_int('depth', 6, 10),\n        'learning_rate': trial.suggest_float('learning_rate', 0.03, 0.1, log=True),\n        'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1, 5),\n        'border_count': trial.suggest_int('border_count', 32, 128),\n        'random_strength': trial.suggest_float('random_strength', 1e-7, 1, log=True),\n        'bagging_temperature': trial.suggest_float('bagging_temperature', 0, 1),\n        'scale_pos_weight': trial.suggest_float('scale_pos_weight', 1, 3),\n        'verbose': 0,\n        'task_type': 'CPU'\n    }\n\n    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n    accuracies = []\n\n    for train_idx, val_idx in skf.split(X_train, y_train):\n        X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n        y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n\n        train_pool = Pool(X_tr, y_tr, cat_features=cat_features)\n        val_pool = Pool(X_val, y_val, cat_features=cat_features)\n\n        model = CatBoostClassifier(**params)\n        model.fit(train_pool, eval_set=val_pool, early_stopping_rounds=100, use_best_model=True)\n\n        preds = model.predict(X_val)\n        acc = (preds == y_val).mean()\n        accuracies.append(acc)\n\n    return np.mean(accuracies)\n\nstudy = optuna.create_study(direction='maximize')\nstudy.optimize(objective, n_trials=30)\n\nprint(f'Best trial accuracy: {study.best_value}')\nprint('Best hyperparameters:', study.best_params)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T11:17:04.660313Z","iopub.execute_input":"2025-06-03T11:17:04.660697Z","iopub.status.idle":"2025-06-03T11:20:08.016488Z","shell.execute_reply.started":"2025-06-03T11:17:04.660671Z","shell.execute_reply":"2025-06-03T11:20:08.015761Z"}},"outputs":[{"name":"stderr","text":"[I 2025-06-03 11:17:04,666] A new study created in memory with name: no-name-a903f0c8-5656-4d98-b495-6b0f473f6dc5\n[I 2025-06-03 11:17:08,634] Trial 0 finished with value: 0.7683992895204262 and parameters: {'iterations': 1710, 'depth': 7, 'learning_rate': 0.03400171723917107, 'l2_leaf_reg': 3.036869644938348, 'border_count': 119, 'random_strength': 0.32042898931348296, 'bagging_temperature': 0.16101012746477572, 'scale_pos_weight': 2.3410194327448197}. Best is trial 0 with value: 0.7683992895204262.\n[I 2025-06-03 11:17:18,332] Trial 1 finished with value: 0.7947040852575489 and parameters: {'iterations': 1695, 'depth': 10, 'learning_rate': 0.06940317379494983, 'l2_leaf_reg': 1.9116193735026434, 'border_count': 71, 'random_strength': 0.6174485786021636, 'bagging_temperature': 0.2181694238616092, 'scale_pos_weight': 1.4770389793924223}. Best is trial 1 with value: 0.7947040852575489.\n[I 2025-06-03 11:17:28,490] Trial 2 finished with value: 0.7859958160647326 and parameters: {'iterations': 1564, 'depth': 10, 'learning_rate': 0.06380025319236776, 'l2_leaf_reg': 2.433844806890273, 'border_count': 90, 'random_strength': 6.939396461314216e-05, 'bagging_temperature': 0.8236824373982393, 'scale_pos_weight': 1.8147599916150596}. Best is trial 1 with value: 0.7947040852575489.\n[I 2025-06-03 11:17:31,813] Trial 3 finished with value: 0.7584461022301163 and parameters: {'iterations': 1816, 'depth': 7, 'learning_rate': 0.06624706993566008, 'l2_leaf_reg': 3.8538192211606193, 'border_count': 62, 'random_strength': 0.00017666802514475766, 'bagging_temperature': 0.7561402282689057, 'scale_pos_weight': 2.687409281314443}. Best is trial 1 with value: 0.7947040852575489.\n[I 2025-06-03 11:17:41,415] Trial 4 finished with value: 0.7746191434774028 and parameters: {'iterations': 1847, 'depth': 10, 'learning_rate': 0.061887795334759466, 'l2_leaf_reg': 2.36141386049226, 'border_count': 42, 'random_strength': 5.655361365763126e-07, 'bagging_temperature': 0.475724242240512, 'scale_pos_weight': 2.2699710785707143}. Best is trial 1 with value: 0.7947040852575489.\n[I 2025-06-03 11:17:46,810] Trial 5 finished with value: 0.7906155121373593 and parameters: {'iterations': 1275, 'depth': 9, 'learning_rate': 0.09998814698385625, 'l2_leaf_reg': 3.438509312949747, 'border_count': 35, 'random_strength': 0.23708329356851787, 'bagging_temperature': 0.31337849233917725, 'scale_pos_weight': 1.535528550814924}. Best is trial 1 with value: 0.7947040852575489.\n[I 2025-06-03 11:17:51,194] Trial 6 finished with value: 0.7870613775409512 and parameters: {'iterations': 1851, 'depth': 8, 'learning_rate': 0.0463790632386517, 'l2_leaf_reg': 3.720299908777311, 'border_count': 32, 'random_strength': 0.003901241243271617, 'bagging_temperature': 0.8705147887065345, 'scale_pos_weight': 1.6051250730625857}. Best is trial 1 with value: 0.7947040852575489.\n[I 2025-06-03 11:18:00,072] Trial 7 finished with value: 0.7618213538582989 and parameters: {'iterations': 1077, 'depth': 10, 'learning_rate': 0.08455143995857474, 'l2_leaf_reg': 1.1088631102932913, 'border_count': 40, 'random_strength': 6.3473565983520725e-06, 'bagging_temperature': 0.9933997044426374, 'scale_pos_weight': 2.7702165567855666}. Best is trial 1 with value: 0.7947040852575489.\n[I 2025-06-03 11:18:03,244] Trial 8 finished with value: 0.763955318729031 and parameters: {'iterations': 1142, 'depth': 6, 'learning_rate': 0.04394745102044641, 'l2_leaf_reg': 4.436588615584834, 'border_count': 118, 'random_strength': 1.6646314084313298e-06, 'bagging_temperature': 0.6854581327803351, 'scale_pos_weight': 2.419355507311156}. Best is trial 1 with value: 0.7947040852575489.\n[I 2025-06-03 11:18:05,690] Trial 9 finished with value: 0.785462640615749 and parameters: {'iterations': 1003, 'depth': 6, 'learning_rate': 0.07140869026870887, 'l2_leaf_reg': 2.7508438917578064, 'border_count': 50, 'random_strength': 0.002591663637798273, 'bagging_temperature': 0.619759547964951, 'scale_pos_weight': 1.7569551853910215}. Best is trial 1 with value: 0.7947040852575489.\n[I 2025-06-03 11:18:13,068] Trial 10 finished with value: 0.7996815472666272 and parameters: {'iterations': 1424, 'depth': 9, 'learning_rate': 0.049270017163639, 'l2_leaf_reg': 1.3972057088217225, 'border_count': 84, 'random_strength': 0.019765707046231325, 'bagging_temperature': 0.022571672641554297, 'scale_pos_weight': 1.0557860435709667}. Best is trial 10 with value: 0.7996815472666272.\n[I 2025-06-03 11:18:19,915] Trial 11 finished with value: 0.8000367870534835 and parameters: {'iterations': 1434, 'depth': 9, 'learning_rate': 0.051331744396649566, 'l2_leaf_reg': 1.3129453124805823, 'border_count': 75, 'random_strength': 0.031098803716490486, 'bagging_temperature': 0.023642638709576447, 'scale_pos_weight': 1.0098587107884718}. Best is trial 11 with value: 0.8000367870534835.\n[I 2025-06-03 11:18:27,154] Trial 12 finished with value: 0.7987932899151372 and parameters: {'iterations': 1337, 'depth': 9, 'learning_rate': 0.04818790044284555, 'l2_leaf_reg': 1.1147270075173972, 'border_count': 90, 'random_strength': 0.019660184984692373, 'bagging_temperature': 0.03221589726840516, 'scale_pos_weight': 1.0533198000601998}. Best is trial 11 with value: 0.8000367870534835.\n[I 2025-06-03 11:18:35,118] Trial 13 finished with value: 0.8009259917110716 and parameters: {'iterations': 1428, 'depth': 9, 'learning_rate': 0.037143342225491295, 'l2_leaf_reg': 1.6957887579018691, 'border_count': 99, 'random_strength': 0.028197032022741972, 'bagging_temperature': 0.0364640867256832, 'scale_pos_weight': 1.0619461367712402}. Best is trial 13 with value: 0.8009259917110716.\n[I 2025-06-03 11:18:40,306] Trial 14 finished with value: 0.797371067692915 and parameters: {'iterations': 1520, 'depth': 8, 'learning_rate': 0.03433892310557828, 'l2_leaf_reg': 1.7927113480596355, 'border_count': 102, 'random_strength': 0.03890983564051342, 'bagging_temperature': 0.35200653869169096, 'scale_pos_weight': 1.2736235429594838}. Best is trial 13 with value: 0.8009259917110716.\n[I 2025-06-03 11:18:48,657] Trial 15 finished with value: 0.7987928162620881 and parameters: {'iterations': 1234, 'depth': 9, 'learning_rate': 0.030207969976246644, 'l2_leaf_reg': 1.7848604282945852, 'border_count': 102, 'random_strength': 0.0015186821973470154, 'bagging_temperature': 0.11242909921638577, 'scale_pos_weight': 1.1789186984090931}. Best is trial 13 with value: 0.8009259917110716.\n[I 2025-06-03 11:18:53,781] Trial 16 finished with value: 0.8007478981645944 and parameters: {'iterations': 1425, 'depth': 8, 'learning_rate': 0.04101019229861252, 'l2_leaf_reg': 2.1206217058390973, 'border_count': 68, 'random_strength': 2.8620005815442997e-05, 'bagging_temperature': 0.3020577853502547, 'scale_pos_weight': 1.3108746883692441}. Best is trial 13 with value: 0.8009259917110716.\n[I 2025-06-03 11:18:57,580] Trial 17 finished with value: 0.7970148805999606 and parameters: {'iterations': 1596, 'depth': 7, 'learning_rate': 0.039978059229066255, 'l2_leaf_reg': 2.260593384176453, 'border_count': 62, 'random_strength': 1.1763782709821843e-05, 'bagging_temperature': 0.4281131166720461, 'scale_pos_weight': 1.3674110889949729}. Best is trial 13 with value: 0.8009259917110716.\n[I 2025-06-03 11:19:03,126] Trial 18 finished with value: 0.7788850207223209 and parameters: {'iterations': 1364, 'depth': 8, 'learning_rate': 0.03751271639437228, 'l2_leaf_reg': 2.8924446683752127, 'border_count': 105, 'random_strength': 5.459261281548881e-05, 'bagging_temperature': 0.2576029177115063, 'scale_pos_weight': 2.027781974383392}. Best is trial 13 with value: 0.8009259917110716.\n[I 2025-06-03 11:19:08,448] Trial 19 finished with value: 0.7819066114071443 and parameters: {'iterations': 1203, 'depth': 8, 'learning_rate': 0.04123940951779452, 'l2_leaf_reg': 4.844401326007041, 'border_count': 61, 'random_strength': 0.0007037497793912214, 'bagging_temperature': 0.38519732501802784, 'scale_pos_weight': 1.9222784200617762}. Best is trial 13 with value: 0.8009259917110716.\n[I 2025-06-03 11:19:11,629] Trial 20 finished with value: 0.7513359384251036 and parameters: {'iterations': 1640, 'depth': 7, 'learning_rate': 0.05695622110337565, 'l2_leaf_reg': 2.0084570979110286, 'border_count': 125, 'random_strength': 1.8312174678920174e-07, 'bagging_temperature': 0.570480285898326, 'scale_pos_weight': 2.967685866925186}. Best is trial 13 with value: 0.8009259917110716.\n[I 2025-06-03 11:19:18,745] Trial 21 finished with value: 0.7996813893822774 and parameters: {'iterations': 1445, 'depth': 9, 'learning_rate': 0.05211977807211046, 'l2_leaf_reg': 1.5268239820442422, 'border_count': 77, 'random_strength': 0.059825945269207155, 'bagging_temperature': 0.10037102750608586, 'scale_pos_weight': 1.0045995729036448}. Best is trial 13 with value: 0.8009259917110716.\n[I 2025-06-03 11:19:26,435] Trial 22 finished with value: 0.8002148805999605 and parameters: {'iterations': 1444, 'depth': 9, 'learning_rate': 0.03618606315637457, 'l2_leaf_reg': 1.4439749310437815, 'border_count': 73, 'random_strength': 0.010666103169455132, 'bagging_temperature': 0.013060299567101863, 'scale_pos_weight': 1.2644395273456155}. Best is trial 13 with value: 0.8009259917110716.\n[I 2025-06-03 11:19:32,125] Trial 23 finished with value: 0.797904558910598 and parameters: {'iterations': 1352, 'depth': 8, 'learning_rate': 0.03021729991409428, 'l2_leaf_reg': 1.634528564653057, 'border_count': 53, 'random_strength': 0.0002639043157971358, 'bagging_temperature': 0.21633175271335597, 'scale_pos_weight': 1.2860764804939548}. Best is trial 13 with value: 0.8009259917110716.\n[I 2025-06-03 11:19:38,022] Trial 24 finished with value: 0.7957716992303139 and parameters: {'iterations': 1978, 'depth': 8, 'learning_rate': 0.03484527613930543, 'l2_leaf_reg': 2.122628098974059, 'border_count': 90, 'random_strength': 0.0065170750693517255, 'bagging_temperature': 0.13098522772324875, 'scale_pos_weight': 1.3932936624527026}. Best is trial 13 with value: 0.8009259917110716.\n[I 2025-06-03 11:19:45,688] Trial 25 finished with value: 0.7902602723505032 and parameters: {'iterations': 1513, 'depth': 9, 'learning_rate': 0.03778824987178841, 'l2_leaf_reg': 2.516642212655709, 'border_count': 68, 'random_strength': 0.1456573267721829, 'bagging_temperature': 0.28429365517010063, 'scale_pos_weight': 1.6299806353492925}. Best is trial 13 with value: 0.8009259917110716.\n[I 2025-06-03 11:19:52,907] Trial 26 finished with value: 0.7968372607065325 and parameters: {'iterations': 1285, 'depth': 9, 'learning_rate': 0.0440503707773397, 'l2_leaf_reg': 1.4612336958731162, 'border_count': 82, 'random_strength': 1.1971805312646107e-05, 'bagging_temperature': 0.000176773681787451, 'scale_pos_weight': 1.2241605268661993}. Best is trial 13 with value: 0.8009259917110716.\n[I 2025-06-03 11:19:58,189] Trial 27 finished with value: 0.800925833826722 and parameters: {'iterations': 1448, 'depth': 8, 'learning_rate': 0.03285139621416207, 'l2_leaf_reg': 1.005768597606787, 'border_count': 97, 'random_strength': 0.009510649912876232, 'bagging_temperature': 0.14150121834857687, 'scale_pos_weight': 1.162859513253652}. Best is trial 13 with value: 0.8009259917110716.\n[I 2025-06-03 11:20:03,623] Trial 28 finished with value: 0.8005698046181173 and parameters: {'iterations': 1631, 'depth': 8, 'learning_rate': 0.03299567791399517, 'l2_leaf_reg': 1.093978452590765, 'border_count': 110, 'random_strength': 0.0006331115852915765, 'bagging_temperature': 0.18588882006934837, 'scale_pos_weight': 1.1433475454797006}. Best is trial 13 with value: 0.8009259917110716.\n[I 2025-06-03 11:20:08,012] Trial 29 finished with value: 0.7758643773435959 and parameters: {'iterations': 1758, 'depth': 7, 'learning_rate': 0.03288420344949639, 'l2_leaf_reg': 3.2894387783792003, 'border_count': 94, 'random_strength': 0.9984729986019144, 'bagging_temperature': 0.1586707911374929, 'scale_pos_weight': 2.125357872898771}. Best is trial 13 with value: 0.8009259917110716.\n","output_type":"stream"},{"name":"stdout","text":"Best trial accuracy: 0.8009259917110716\nBest hyperparameters: {'iterations': 1428, 'depth': 9, 'learning_rate': 0.037143342225491295, 'l2_leaf_reg': 1.6957887579018691, 'border_count': 99, 'random_strength': 0.028197032022741972, 'bagging_temperature': 0.0364640867256832, 'scale_pos_weight': 1.0619461367712402}\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"# Assuming cat_features is correct and defined properly\n\nmodel = CatBoostClassifier(\n    iterations=3000,\n    depth=9,\n    learning_rate=0.037,\n    l2_leaf_reg=1.7,\n    border_count=99,\n    random_strength=0.028,\n    bagging_temperature=0.036,\n    scale_pos_weight=1.06,\n    early_stopping_rounds=200,\n    verbose=100,\n)\n\nmodel.fit(\n    Pool(X_train, y_train, cat_features=cat_features),\n    eval_set=Pool(X_test, y_test, cat_features=cat_features),\n    use_best_model=True,\n)\n\n# Predict probabilities\nprobs = model.predict_proba(X_test)[:, 1]\n\n# Threshold tuning\nbest_acc = 0\nbest_thresh = 0.5\nfor thresh in np.arange(0.3, 0.8, 0.01):\n    preds = (probs >= thresh).astype(int)\n    acc = (preds == y_test).mean()\n    if acc > best_acc:\n        best_acc = acc\n        best_thresh = thresh\n\nprint(f\"Best threshold: {best_thresh}, Best accuracy: {best_acc:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T11:20:55.724485Z","iopub.execute_input":"2025-06-03T11:20:55.724868Z","iopub.status.idle":"2025-06-03T11:21:22.747781Z","shell.execute_reply.started":"2025-06-03T11:20:55.724843Z","shell.execute_reply":"2025-06-03T11:21:22.746896Z"}},"outputs":[{"name":"stdout","text":"0:\tlearn: 0.6656348\ttest: 0.6659893\tbest: 0.6659893 (0)\ttotal: 10.4ms\tremaining: 31.3s\n100:\tlearn: 0.3165868\ttest: 0.3445657\tbest: 0.3445657 (100)\ttotal: 875ms\tremaining: 25.1s\n200:\tlearn: 0.2600154\ttest: 0.2984984\tbest: 0.2984984 (200)\ttotal: 1.74s\tremaining: 24.2s\n300:\tlearn: 0.2189641\ttest: 0.2659815\tbest: 0.2659815 (300)\ttotal: 2.6s\tremaining: 23.4s\n400:\tlearn: 0.1880207\ttest: 0.2413115\tbest: 0.2413115 (400)\ttotal: 3.47s\tremaining: 22.5s\n500:\tlearn: 0.1643782\ttest: 0.2240570\tbest: 0.2240570 (500)\ttotal: 4.34s\tremaining: 21.6s\n600:\tlearn: 0.1440364\ttest: 0.2082914\tbest: 0.2082914 (600)\ttotal: 5.2s\tremaining: 20.8s\n700:\tlearn: 0.1277506\ttest: 0.1955338\tbest: 0.1955338 (700)\ttotal: 6.08s\tremaining: 19.9s\n800:\tlearn: 0.1133948\ttest: 0.1848721\tbest: 0.1848721 (800)\ttotal: 6.98s\tremaining: 19.2s\n900:\tlearn: 0.1024955\ttest: 0.1768697\tbest: 0.1768697 (900)\ttotal: 7.85s\tremaining: 18.3s\n1000:\tlearn: 0.0922786\ttest: 0.1691632\tbest: 0.1691632 (1000)\ttotal: 8.72s\tremaining: 17.4s\n1100:\tlearn: 0.0834495\ttest: 0.1629348\tbest: 0.1629348 (1100)\ttotal: 9.59s\tremaining: 16.5s\n1200:\tlearn: 0.0765040\ttest: 0.1577726\tbest: 0.1577655 (1199)\ttotal: 10.5s\tremaining: 15.7s\n1300:\tlearn: 0.0705390\ttest: 0.1541441\tbest: 0.1541441 (1300)\ttotal: 11.3s\tremaining: 14.8s\n1400:\tlearn: 0.0653101\ttest: 0.1512020\tbest: 0.1512020 (1400)\ttotal: 12.2s\tremaining: 13.9s\n1500:\tlearn: 0.0610379\ttest: 0.1488682\tbest: 0.1488682 (1500)\ttotal: 13s\tremaining: 13s\n1600:\tlearn: 0.0571188\ttest: 0.1468549\tbest: 0.1468469 (1595)\ttotal: 14s\tremaining: 12.2s\n1700:\tlearn: 0.0535032\ttest: 0.1451085\tbest: 0.1450479 (1697)\ttotal: 14.9s\tremaining: 11.4s\n1800:\tlearn: 0.0502776\ttest: 0.1438246\tbest: 0.1438246 (1800)\ttotal: 15.8s\tremaining: 10.5s\n1900:\tlearn: 0.0473071\ttest: 0.1420734\tbest: 0.1420665 (1893)\ttotal: 16.7s\tremaining: 9.65s\n2000:\tlearn: 0.0446648\ttest: 0.1407993\tbest: 0.1407993 (2000)\ttotal: 17.6s\tremaining: 8.77s\n2100:\tlearn: 0.0424362\ttest: 0.1392778\tbest: 0.1392662 (2098)\ttotal: 18.4s\tremaining: 7.89s\n2200:\tlearn: 0.0404868\ttest: 0.1384662\tbest: 0.1384237 (2183)\ttotal: 19.3s\tremaining: 7.01s\n2300:\tlearn: 0.0385541\ttest: 0.1375746\tbest: 0.1375746 (2300)\ttotal: 20.2s\tremaining: 6.13s\n2400:\tlearn: 0.0367391\ttest: 0.1368989\tbest: 0.1368833 (2393)\ttotal: 21.1s\tremaining: 5.25s\n2500:\tlearn: 0.0351761\ttest: 0.1364377\tbest: 0.1364311 (2497)\ttotal: 21.9s\tremaining: 4.37s\n2600:\tlearn: 0.0338014\ttest: 0.1363149\tbest: 0.1362953 (2598)\ttotal: 22.8s\tremaining: 3.5s\n2700:\tlearn: 0.0324546\ttest: 0.1362975\tbest: 0.1362151 (2626)\ttotal: 23.7s\tremaining: 2.62s\n2800:\tlearn: 0.0312547\ttest: 0.1361833\tbest: 0.1361618 (2750)\ttotal: 24.5s\tremaining: 1.74s\n2900:\tlearn: 0.0299372\ttest: 0.1357423\tbest: 0.1357243 (2889)\ttotal: 25.4s\tremaining: 867ms\n2999:\tlearn: 0.0289023\ttest: 0.1358409\tbest: 0.1356148 (2981)\ttotal: 26.3s\tremaining: 0us\n\nbestTest = 0.1356147899\nbestIteration = 2981\n\nShrink model to first 2982 iterations.\nBest threshold: 0.4500000000000001, Best accuracy: 0.9574\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"import joblib\n\n# Save CatBoost model\nmodel.save_model(\"catboost_churn_model.cbm\")\n\n# Save best threshold\njoblib.dump(best_thresh, \"best_threshold.pkl\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T11:28:46.808709Z","iopub.execute_input":"2025-06-03T11:28:46.809063Z","iopub.status.idle":"2025-06-03T11:28:46.930727Z","shell.execute_reply.started":"2025-06-03T11:28:46.809041Z","shell.execute_reply":"2025-06-03T11:28:46.929605Z"}},"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"['best_threshold.pkl']"},"metadata":{}}],"execution_count":22},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}